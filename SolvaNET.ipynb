{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo8WznxNdqD9"
      },
      "source": [
        "#  <center> SolvaNET: Final Project <center>\n",
        "\n",
        "<center> 10.C51 <center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbRz3p9WdqD_",
        "outputId": "48438f74-fc58-4cb8-d49c-0e1a5ca96c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.6\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yzHDk2idqEE",
        "outputId": "a181c5fe-6d29-4ece-f6ef-02c7806c20e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-05-10 01:51:25--  https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps6-sfe/data/molecule_props.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26739 (26K) [text/plain]\n",
            "Saving to: ‘molecule_props.csv’\n",
            "\n",
            "molecule_props.csv  100%[===================>]  26.11K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-10 01:51:25 (141 MB/s) - ‘molecule_props.csv’ saved [26739/26739]\n",
            "\n",
            "--2024-05-10 01:51:25--  https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps6-sfe/data/solvation_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 124274 (121K) [text/plain]\n",
            "Saving to: ‘solvation_train.csv’\n",
            "\n",
            "solvation_train.csv 100%[===================>] 121.36K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-05-10 01:51:26 (34.2 MB/s) - ‘solvation_train.csv’ saved [124274/124274]\n",
            "\n",
            "--2024-05-10 01:51:26--  https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps6-sfe/data/solvation_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37639 (37K) [text/plain]\n",
            "Saving to: ‘solvation_test.csv’\n",
            "\n",
            "solvation_test.csv  100%[===================>]  36.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-10 01:51:26 (126 MB/s) - ‘solvation_test.csv’ saved [37639/37639]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps6-sfe/data/molecule_props.csv\n",
        "!wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps6-sfe/data/solvation_train.csv\n",
        "!wget https://raw.githubusercontent.com/coleygroup/ML4MolEng/main/psets/ps6-sfe/data/solvation_test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxigwz2IsTFp",
        "outputId": "03037f9b-28fe-4846-badf-d4afd54391e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem, Descriptors,Crippen\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "!pip install torch_geometric\n",
        "import torch_geometric\n",
        "from tqdm import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkB_bDgydqEJ"
      },
      "source": [
        "## Part 1: Baseline Regression Methods"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BZBbezSgeV9i"
      },
      "source": [
        "### Part 1.1: Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MSTRFRzdqEL",
        "outputId": "0f4d9bb6-2aa7-4d3a-df23-b307f5fe774c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Solvent             Solute   logK  deltaG_solv\n",
            "0      C(Cl)(Cl)(Cl)Cl       c1ccc(cc1)CO  4.830     -0.28574\n",
            "1         c1ccc(cc1)Br               CCCO  2.760     -0.16328\n",
            "2         CC(C)CC(=O)C       CC(Cl)(Cl)Cl  3.134     -0.18541\n",
            "3           CC(C)(C)OC  C(C(F)(F)F)(Cl)Br  3.440     -0.20351\n",
            "4              CC(=O)C         CC(C)(C)Cl  2.540     -0.15026\n",
            "...                ...                ...    ...          ...\n",
            "3653          CN(C)C=O              C(F)F  1.240     -0.07336\n",
            "3654         Cc1ccccc1       CCCCCC(=O)OC  4.676     -0.27663\n",
            "3655  CCCCCCCCCCCCCCCC            CCCCCCN  3.557     -0.21043\n",
            "3656   C(Cl)(Cl)(Cl)Cl      c1ccc(cc1)C=O  4.480     -0.26503\n",
            "3657  CCCCCCCCCCCCCCCC       CC(C)CC(=O)O  3.300     -0.19523\n",
            "\n",
            "[3658 rows x 4 columns]\n",
            "             SMILES  chiral  mol_weight  polarizability    dipole\n",
            "0           CCC(C)O       1       74.12            8.81  1.646671\n",
            "1          C1COCCO1       0       88.11            8.70  1.477152\n",
            "2         CCCCCCCCO       0      130.23           16.51  1.596122\n",
            "3              CCCO       0       60.10            6.90  1.441882\n",
            "4    CC(C)CC(C)(C)C       0      114.23           15.53  0.115803\n",
            "..              ...     ...         ...             ...       ...\n",
            "652      CC(C)CCC=C       0       98.19           13.73  0.530052\n",
            "653    CC(C)(C)CC=C       0       98.19           13.55  0.460670\n",
            "654               P       0       34.00            4.44  0.558540\n",
            "655        CCC(=C)C       0       70.13            9.80  0.589047\n",
            "656       CCCC(=C)C       0       84.16           11.58  0.616587\n",
            "\n",
            "[657 rows x 5 columns]\n",
            "      index                 Solvent            Solute\n",
            "0         0                  CCCCCO              [Ne]\n",
            "1         1          CC(C)CC(C)(C)C             CCCCO\n",
            "2         2  c1ccc(cc1)[N+](=O)[O-]         Cc1ccccc1\n",
            "3         3             C/C(=N/C)/O            CC(C)O\n",
            "4         4               CCOC(=O)C            CCCCCC\n",
            "...     ...                     ...               ...\n",
            "1564   1564                  CCCCCC  c1ccc(c(c1)Cl)Cl\n",
            "1565   1565               CC(C)(C)O           C(=O)=O\n",
            "1566   1566                  CCCOCC                CO\n",
            "1567   1567                 CCCCCCC            CCCC=C\n",
            "1568   1568                CCCCCCCC      Cc1ccc(cc1)N\n",
            "\n",
            "[1569 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "train_data = pd.read_csv('./solvation_train.csv')\n",
        "mol_prop = pd.read_csv('./molecule_props.csv')\n",
        "test_data = pd.read_csv('./solvation_test.csv')\n",
        "print(train_data)\n",
        "print(mol_prop)\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok9EthEXec48"
      },
      "source": [
        "Some utility functions for you to generate features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMYXzNLCepen"
      },
      "source": [
        "Generate fingerprints (e.g. a Morgan fingerprint)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zL8tJad6dqEU"
      },
      "outputs": [],
      "source": [
        "# Get molecular feature from RDkit\n",
        "smiles = 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C'\n",
        "\n",
        "# define Mol object\n",
        "mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "# get morgan fingerprint\n",
        "# obtain a 512 bit fingperint, with radius 2\n",
        "fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=512)\n",
        "\n",
        "# convert to numpy array\n",
        "fp_array = np.zeros((1,), int)\n",
        "DataStructs.ConvertToNumpyArray(fp, fp_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tItagId2erRw"
      },
      "source": [
        "Generate various chemical properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jU2HiX0hdqEZ"
      },
      "outputs": [],
      "source": [
        "MolWt = Descriptors.ExactMolWt(mol)\n",
        "TPSA = Chem.rdMolDescriptors.CalcTPSA(mol) #Topological Polar Surface Area\n",
        "nRotB = Descriptors.NumRotatableBonds(mol) #Number of rotable bonds\n",
        "HBD = Descriptors.NumHDonors(mol) #Number of H bond donors\n",
        "HBA = Descriptors.NumHAcceptors(mol) #Number of H bond acceptors\n",
        "logP = Descriptors.MolLogP(mol) #LogP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkl6NBhJew2K"
      },
      "source": [
        "Create a feature set with concatenated physical descriptors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj-SFjPee0My",
        "outputId": "78d01098-0662-4a11-84f5-93ab6a2a6e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3658, 1314)\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "#creating numpy array of one hot encoded labels for solvent-solute pairs\n",
        "#similar to pset 2\n",
        "\n",
        "#TRAIN DATA\n",
        "# Extract columns solvents and solutes\n",
        "col_solvent_tr = train_data['Solvent']\n",
        "col_solute_tr = train_data['Solute']\n",
        "y_tr = train_data['logK']\n",
        "\n",
        "# Initialize LabelBinarizer\n",
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(mol_prop['SMILES'])\n",
        "\n",
        "# Binarize column A and B\n",
        "bit_vectors_solvent_tr = label_binarizer.transform(col_solvent_tr)\n",
        "bit_vectors_solute_tr = label_binarizer.transform(col_solute_tr)\n",
        "\n",
        "# Stack bit vectors horizontally\n",
        "stacked_train = np.hstack((bit_vectors_solvent_tr, bit_vectors_solute_tr))\n",
        "\n",
        "#TEST DATA\n",
        "# Extract columns solvents and solutes\n",
        "col_solvent_te = test_data['Solvent']\n",
        "col_solute_te = test_data['Solute']\n",
        "\n",
        "\n",
        "bit_vectors_solvent_te = label_binarizer.transform(col_solvent_te)\n",
        "bit_vectors_solute_te = label_binarizer.transform(col_solute_te)\n",
        "\n",
        "stacked_test = np.hstack((bit_vectors_solvent_te, bit_vectors_solute_te))\n",
        "\n",
        "print(stacked_train.shape)\n",
        "print(stacked_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjCgpXyl12sW"
      },
      "source": [
        "create numpy arrays of raw descriptors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fWBkc-xCyXqV"
      },
      "outputs": [],
      "source": [
        "# helper functions\n",
        "\n",
        "def get_item(smiles_list, mol_prop_data, feature):\n",
        "  '''\n",
        "  smiles_list: list of SMILES strings\n",
        "  mol_prop_data: pandas DataFrame containing molecular properties\n",
        "  feature: string specifying the molecular property to extract\n",
        "\n",
        "  returns: numpy array of molecular properties\n",
        "  '''\n",
        "  # Initialize an empty list to store the molecular properties\n",
        "  prop_list = []\n",
        "\n",
        "  # Iterate over each SMILES string\n",
        "  for smiles in smiles_list:\n",
        "      # Find the row corresponding to the SMILES string in the DataFrame\n",
        "      row = mol_prop_data[mol_prop_data['SMILES'] == smiles]\n",
        "\n",
        "      # Check if the SMILES string exists in the DataFrame\n",
        "      if not row.empty:\n",
        "          # Extract the value of the specified molecular property\n",
        "          prop_value = row[feature].values[0]\n",
        "          # Append the property value to the list\n",
        "          prop_list.append(prop_value)\n",
        "      else:\n",
        "          # If the SMILES string is not found, append NaN (or any other placeholder)\n",
        "          prop_list.append(np.nan)\n",
        "\n",
        "  # Convert the list of molecular properties to a numpy array\n",
        "  prop_array = np.array(prop_list)\n",
        "\n",
        "  return prop_array\n",
        "\n",
        "#deal with NaN\n",
        "def fill_nan_with_mean(array):\n",
        "  '''\n",
        "  array: numpy array of raw descriptors\n",
        "  returns: numpy array with NaN values filled with the mean of the non-NaN values\n",
        "  '''\n",
        "  # Calculate the mean of the non-NaN values\n",
        "  mean_val = np.nanmean(array[~np.isnan(array)])\n",
        "\n",
        "  # Replace NaN values with the mean\n",
        "  array[np.isnan(array)] = mean_val\n",
        "\n",
        "  return array\n",
        "\n",
        "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
        "def get_raw_desc(smiles_list, feature):\n",
        "    '''\n",
        "    smiles_list: list of SMILES strings\n",
        "    feature: string specifying the molecular property to extract\n",
        "\n",
        "    returns: numpy array of molecular properties\n",
        "    '''\n",
        "    # Pre-calculate molecule objects for all SMILES strings\n",
        "    mol_list = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
        "\n",
        "    # Initialize a dictionary mapping features to descriptor functions\n",
        "    descriptor_functions = {\n",
        "        'TPSA': rdMolDescriptors.CalcTPSA,\n",
        "        'nRotB': Descriptors.NumRotatableBonds,\n",
        "        'HBD': Descriptors.NumHDonors,\n",
        "        'HBA': Descriptors.NumHAcceptors,\n",
        "        'logP': Descriptors.MolLogP\n",
        "    }\n",
        "\n",
        "    # Get the appropriate descriptor function for the specified feature\n",
        "    descriptor_function = descriptor_functions.get(feature)\n",
        "\n",
        "    if descriptor_function is None:\n",
        "        raise ValueError(\"Invalid feature name\")\n",
        "\n",
        "    # Calculate molecular properties using the selected descriptor function\n",
        "    prop_list = [descriptor_function(mol) for mol in mol_list if mol is not None]\n",
        "\n",
        "    # Convert the list of molecular properties to a numpy array\n",
        "    prop_array = np.array(prop_list)\n",
        "\n",
        "    return prop_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1Yq6jh50dKR",
        "outputId": "57e57324-145c-4932-d2e7-f04612074a21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:49] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:50] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:57] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n",
            "[01:52:58] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        }
      ],
      "source": [
        "#TRAIN DATA\n",
        "# create numpy arrays for solvent\n",
        "solvent_mw_tr = fill_nan_with_mean(get_item(train_data['Solvent'], mol_prop, 'mol_weight'))\n",
        "solvent_polarity_tr = fill_nan_with_mean(get_item(train_data['Solvent'], mol_prop, 'polarizability'))\n",
        "solvent_dipole_tr = fill_nan_with_mean(get_item(train_data['Solvent'], mol_prop, 'dipole'))\n",
        "solvent_chiral_tr = fill_nan_with_mean(get_item(train_data['Solvent'], mol_prop, 'chiral'))\n",
        "solvent_tpsa_tr = fill_nan_with_mean(get_raw_desc(train_data['Solvent'], 'TPSA'))\n",
        "solvent_nrotb_tr = fill_nan_with_mean(get_raw_desc(train_data['Solvent'], 'nRotB'))\n",
        "solvent_hbd_tr = fill_nan_with_mean(get_raw_desc(train_data['Solvent'], 'HBD'))\n",
        "solvent_hba_tr = fill_nan_with_mean(get_raw_desc(train_data['Solvent'], 'HBA'))\n",
        "solvent_logp_tr = fill_nan_with_mean(get_raw_desc(train_data['Solvent'], 'logP'))\n",
        "\n",
        "#create numpy arrays for solute\n",
        "solute_mw_tr = fill_nan_with_mean(get_item(train_data['Solute'], mol_prop, 'mol_weight'))\n",
        "solute_polarity_tr = fill_nan_with_mean(get_item(train_data['Solute'], mol_prop, 'polarizability'))\n",
        "solute_dipole_tr = fill_nan_with_mean(get_item(train_data['Solute'], mol_prop, 'dipole'))\n",
        "solute_chiral_tr = fill_nan_with_mean(get_item(train_data['Solute'], mol_prop, 'chiral'))\n",
        "solute_tpsa_tr = fill_nan_with_mean(get_raw_desc(train_data['Solute'], 'TPSA'))\n",
        "solute_nrotb_tr = fill_nan_with_mean(get_raw_desc(train_data['Solute'], 'nRotB'))\n",
        "solute_hbd_tr = fill_nan_with_mean(get_raw_desc(train_data['Solute'], 'HBD'))\n",
        "solute_hba_tr = fill_nan_with_mean(get_raw_desc(train_data['Solute'], 'HBA'))\n",
        "solute_logp_tr = fill_nan_with_mean(get_raw_desc(train_data['Solute'], 'logP'))\n",
        "\n",
        "\n",
        "\n",
        "#TEST DATA\n",
        "solvent_mw_te = fill_nan_with_mean(get_item(test_data['Solvent'], mol_prop, 'mol_weight'))\n",
        "solvent_polarity_te = fill_nan_with_mean(get_item(test_data['Solvent'], mol_prop, 'polarizability'))\n",
        "solvent_dipole_te = fill_nan_with_mean(get_item(test_data['Solvent'], mol_prop, 'dipole'))\n",
        "solvent_chiral_te = fill_nan_with_mean(get_item(test_data['Solvent'], mol_prop, 'chiral'))\n",
        "solvent_tpsa_te = fill_nan_with_mean(get_raw_desc(test_data['Solvent'], 'TPSA'))\n",
        "solvent_nrotb_te = fill_nan_with_mean(get_raw_desc(test_data['Solvent'], 'nRotB'))\n",
        "solvent_hbd_te = fill_nan_with_mean(get_raw_desc(test_data['Solvent'], 'HBD'))\n",
        "solvent_hba_te = fill_nan_with_mean(get_raw_desc(test_data['Solvent'], 'HBA'))\n",
        "solvent_logp_te = fill_nan_with_mean(get_raw_desc(test_data['Solvent'], 'logP'))\n",
        "\n",
        "solute_mw_te = fill_nan_with_mean(get_item(test_data['Solute'], mol_prop, 'mol_weight'))\n",
        "solute_polarity_te = fill_nan_with_mean(get_item(test_data['Solute'], mol_prop, 'polarizability'))\n",
        "solute_dipole_te = fill_nan_with_mean(get_item(test_data['Solute'], mol_prop, 'dipole'))\n",
        "solute_chiral_te = fill_nan_with_mean(get_item(test_data['Solute'], mol_prop, 'chiral'))\n",
        "solute_tpsa_te = fill_nan_with_mean(get_raw_desc(test_data['Solute'], 'TPSA'))\n",
        "solute_nrotb_te = fill_nan_with_mean(get_raw_desc(test_data['Solute'], 'nRotB'))\n",
        "solute_hbd_te = fill_nan_with_mean(get_raw_desc(test_data['Solute'], 'HBD'))\n",
        "solute_hba_te = fill_nan_with_mean(get_raw_desc(test_data['Solute'], 'HBA'))\n",
        "solute_logp_te = fill_nan_with_mean(get_raw_desc(test_data['Solute'], 'logP'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ntpuf7i6GY6",
        "outputId": "ba613905-ba4a-4f74-c4fa-52eda5852915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[153.82       108.14        10.61       ...   1.           2.5529\n",
            "    1.1789    ]\n",
            " [157.01        60.1         13.25       ...   1.           2.4491\n",
            "    0.3887    ]\n",
            " [100.16       133.4         12.06       ...   0.           1.6215\n",
            "    2.3765    ]\n",
            " ...\n",
            " [226.44       101.19        11.23448246 ...   1.           6.4876\n",
            "    1.5254    ]\n",
            " [153.82       106.12        10.61       ...   1.           2.5529\n",
            "    1.4991    ]\n",
            " [226.44       102.13        11.23448246 ...   1.           6.4876\n",
            "    1.1171    ]]\n"
          ]
        }
      ],
      "source": [
        "#combine numpy arrays\n",
        "#TRAIN DATA\n",
        "X_train_uns = np.column_stack((solvent_mw_tr, solute_mw_tr,\n",
        "                               solvent_polarity_tr, solute_polarity_tr,\n",
        "                               solvent_dipole_tr, solute_dipole_tr,\n",
        "                               solvent_chiral_tr, solute_chiral_tr,\n",
        "                               solvent_tpsa_tr, solute_tpsa_tr,\n",
        "                               solvent_nrotb_tr, solute_nrotb_tr,\n",
        "                               solvent_hbd_tr, solute_hbd_tr,\n",
        "                               solvent_hba_tr, solute_hba_tr,\n",
        "                               solvent_logp_tr, solute_logp_tr))\n",
        "\n",
        "#TEST DATA\n",
        "X_test_uns = np.column_stack((solvent_mw_te, solute_mw_te,\n",
        "                              solvent_polarity_te, solute_polarity_te,\n",
        "                              solvent_dipole_te, solute_dipole_te,\n",
        "                              solvent_chiral_te, solute_chiral_te,\n",
        "                              solvent_tpsa_te, solute_tpsa_te,\n",
        "                              solvent_nrotb_te, solute_nrotb_te,\n",
        "                              solvent_hbd_te, solute_hbd_te,\n",
        "                              solvent_hba_te, solute_hba_te,\n",
        "                              solvent_logp_te, solute_logp_te))\n",
        "\n",
        "print(X_train_uns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seNKLaOy0ahA",
        "outputId": "d20cd982-81ac-4f0d-e0c2-a763d69dd380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1569, 18)\n"
          ]
        }
      ],
      "source": [
        "#normalize\n",
        "\n",
        "#TRAIN DATA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_1 = scaler.fit_transform(X_train_uns)\n",
        "X_test_final = scaler.transform(X_test_uns)\n",
        "# print(X_train_1)\n",
        "# print(X_test_final)\n",
        "print(X_test_final.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOVlvHaq52In"
      },
      "source": [
        "### Morgan fingerprint data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GZR9IEKH569Y"
      },
      "outputs": [],
      "source": [
        "# helper function\n",
        "\n",
        "def get_fingerprint_features(smiles_list):\n",
        "  fingerprint_list = []\n",
        "  for smiles in smiles_list:\n",
        "\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=100)\n",
        "    fp_array = np.zeros((1,), int)\n",
        "    DataStructs.ConvertToNumpyArray(fp, fp_array)\n",
        "    fingerprint_list.append(fp_array)\n",
        "  fingerprint_array = np.array(fingerprint_list)\n",
        "  return fingerprint_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcuwGvdm6CWl",
        "outputId": "12a448b2-aeab-48d4-ff76-8aeaedb4b56a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:26] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:27] WARNING: not removing hydrogen atom without neighbors\n",
            "[02:20:27] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        }
      ],
      "source": [
        "# great fp data as numpy arrays\n",
        "\n",
        "# TRAIN DATA\n",
        "solvent_fp_tr = get_fingerprint_features(train_data['Solvent'])\n",
        "solute_fp_tr = get_fingerprint_features(train_data['Solute'])\n",
        "\n",
        "# TEST DATA\n",
        "solvent_fp_te = get_fingerprint_features(test_data['Solvent'])\n",
        "solute_fp_te = get_fingerprint_features(test_data['Solute'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24CFa4Ys6OTi",
        "outputId": "81d058d6-2700-4d27-b86b-a50992ffee8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3658, 218)\n"
          ]
        }
      ],
      "source": [
        "X_train_fp = np.column_stack([X_train_1, solvent_fp_tr, solute_fp_tr])\n",
        "\n",
        "X_test_fp = np.column_stack([X_test_final, solvent_fp_te, solute_fp_te])\n",
        "print(X_train_fp.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu20Gw7Wzpyr"
      },
      "source": [
        "### Mordred data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnK6mkTkztTI",
        "outputId": "26fc4732-8c43-472d-e1f8-8d106bd7e353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mordred\n",
            "  Downloading mordred-1.2.0.tar.gz (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six==1.* in /usr/local/lib/python3.10/dist-packages (from mordred) (1.16.0)\n",
            "Requirement already satisfied: numpy==1.* in /usr/local/lib/python3.10/dist-packages (from mordred) (1.25.2)\n",
            "Collecting networkx==2.* (from mordred)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mordred\n",
            "  Building wheel for mordred (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mordred: filename=mordred-1.2.0-py3-none-any.whl size=176720 sha256=fe9c7f1497eddc843945497bff0c15db1bda7476243f50ba1a5c8bcb5e781840\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/4f/b8/d4c6591f6ac944aaced7865b349477695f662388ad958743c7\n",
            "Successfully built mordred\n",
            "Installing collected packages: networkx, mordred\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mordred-1.2.0 networkx-2.8.8\n"
          ]
        }
      ],
      "source": [
        "pip install mordred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiEIvkIh-c-w",
        "outputId": "bc519d9b-8131-4a2a-e678-506474b93112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hydrophilic Surface Area: 0.0\n",
            "Hydrophobic Surface Area: 5.106527394840706\n",
            "Topological Descriptors: 1.6329931618554523\n",
            "Topological Descriptors: 2.7548875021634682\n",
            "Volume: 0.4297125471872351\n",
            "Spherocity: 0.4966664137659443\n"
          ]
        }
      ],
      "source": [
        "from mordred import Calculator, descriptors\n",
        "from rdkit import Chem\n",
        "\n",
        "# Load your molecule (assuming it's in SMILES format)\n",
        "mol = Chem.MolFromSmiles(\"CCO\")\n",
        "\n",
        "# Create a descriptor calculator instance\n",
        "calc = Calculator(descriptors, ignore_3D=True)  # Ignore 3D descriptors for now\n",
        "\n",
        "# Calculate descriptors\n",
        "descriptors = calc(mol)\n",
        "\n",
        "# Extract specific descriptors\n",
        "hydrophilic_surface_area = descriptors['SlogP_VSA1']\n",
        "hydrophobic_surface_area = descriptors['SMR_VSA1']\n",
        "topological_descriptors_1 = descriptors['BalabanJ']\n",
        "topological_descriptors_2 = descriptors['BertzCT']\n",
        "# Extract more descriptors as needed\n",
        "\n",
        "# Print or use the calculated descriptors\n",
        "print(\"Hydrophilic Surface Area:\", hydrophilic_surface_area)\n",
        "print(\"Hydrophobic Surface Area:\", hydrophobic_surface_area)\n",
        "print(\"Topological Descriptors:\", topological_descriptors_1)\n",
        "print(\"Topological Descriptors:\", topological_descriptors_2)\n",
        "\n",
        "from rdkit.Chem import Descriptors3D\n",
        "# Generate 3D conformer\n",
        "mol = Chem.AddHs(mol)\n",
        "AllChem.EmbedMolecule(mol, AllChem.ETKDG())\n",
        "AllChem.UFFOptimizeMolecule(mol)\n",
        "\n",
        "# Calculate 3D shape descriptors\n",
        "volume = Descriptors3D.Asphericity(mol)\n",
        "spherocity = Descriptors3D.SpherocityIndex(mol)\n",
        "\n",
        "\n",
        "# Print or use the calculated descriptors\n",
        "print(\"Volume:\", volume)\n",
        "print(\"Spherocity:\", spherocity)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sORacKvLNOft"
      },
      "outputs": [],
      "source": [
        "# helper function for mordred data\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from mordred import Calculator, descriptors\n",
        "\n",
        "def get_mordred_desc(smiles_list, feature):\n",
        "    '''\n",
        "    smiles_list: list of SMILES strings\n",
        "    feature: string specifying the molecular property to extract\n",
        "\n",
        "    returns: numpy array of molecular properties\n",
        "    '''\n",
        "    mordred_list = []\n",
        "    for smiles in smiles_list:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        # Create a descriptor calculator instance\n",
        "        calc = Calculator(descriptors, ignore_3D=True)  # Ignore 3D descriptors for now\n",
        "\n",
        "        # Calculate descriptors\n",
        "        descriptors_1 = calc(mol)\n",
        "        if feature == 'SlogP_VSA1':\n",
        "          mordred_list.append(descriptors_1['SlogP_VSA1'])\n",
        "        if feature == 'SMR_VSA1':\n",
        "          mordred_list.append(descriptors_1['SMR_VSA1'])\n",
        "        if feature == 'BalabanJ':\n",
        "          mordred_list.append(descriptors_1['BalabanJ'])\n",
        "        if feature == 'BertzCT':\n",
        "          mordred_list.append(descriptors_1['BertzCT'])\n",
        "    return np.array(mordred_list)\n",
        "\n",
        "def mordred_geometric(smiles_list, feature):\n",
        "    '''\n",
        "    smiles_list: list of SMILES strings\n",
        "    feature: string specifying the 3D geometric property to calculate\n",
        "\n",
        "    returns: numpy array of 3D geometric properties\n",
        "    '''\n",
        "    mordred_list = []\n",
        "    for smiles in smiles_list:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            continue  # Skip invalid molecules\n",
        "\n",
        "        # Generate 3D conformer\n",
        "        mol = Chem.AddHs(mol)\n",
        "        AllChem.EmbedMolecule(mol, AllChem.ETKDG())\n",
        "        AllChem.UFFOptimizeMolecule(mol)\n",
        "\n",
        "        if feature == 'Asphericity':\n",
        "            mordred_list.append(Descriptors3D.Asphericity(mol))\n",
        "        elif feature == 'SpherocityIndex':\n",
        "            mordred_list.append(Descriptors3D.SpherocityIndex(mol))\n",
        "\n",
        "    return np.array(mordred_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "L16uPjG1O37s",
        "outputId": "08c47a15-cd85-42b0-b74c-2e509d784c9f"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0cc2dc0c3f7c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msolvent_mord1_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_nan_with_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_mordred_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Solvent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SlogP_VSA1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msolvent_mord2_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_nan_with_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_mordred_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Solvent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SMR_VSA1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msolvent_mord3_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_nan_with_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_mordred_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Solvent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BalabanJ'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msolvent_mord4_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_nan_with_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_mordred_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Solvent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BertzCT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msolvent_3d_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_nan_with_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmordred_geometric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Solvent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Asphericity'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-1d907e974140>\u001b[0m in \u001b[0;36mget_mordred_desc\u001b[0;34m(smiles_list, feature)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Calculate descriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdescriptors_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SlogP_VSA1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0mmordred_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptors_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SlogP_VSA1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mordred/_base/calculator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, mol, id)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miterator\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdescriptor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         return self._wrap_result(\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mordred/_base/calculator.py\u001b[0m in \u001b[0;36m_wrap_result\u001b[0;34m(self, mol, r)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_descriptors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_serial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mordred/_base/result.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mol, r, d)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_descriptors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_to_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mordred/_base/calculator.py\u001b[0m in \u001b[0;36m_calculate\u001b[0;34m(self, cxt)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mordred/_base/calculator.py\u001b[0m in \u001b[0;36m_calculate_one\u001b[0;34m(self, cxt, desc, reset)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mordred/_base/calculator.py\u001b[0m in \u001b[0;36m_calculate_one\u001b[0;34m(self, cxt, desc, reset)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_debug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_rtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mordred/_atomic_property.py\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matoms_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mnans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0matms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetSymbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnans\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "solvent_mord1_tr = fill_nan_with_mean(get_mordred_desc(train_data['Solvent'], 'SlogP_VSA1'))\n",
        "solvent_mord2_tr = fill_nan_with_mean(get_mordred_desc(train_data['Solvent'], 'SMR_VSA1'))\n",
        "solvent_mord3_tr = fill_nan_with_mean(get_mordred_desc(train_data['Solvent'], 'BalabanJ'))\n",
        "solvent_mord4_tr = fill_nan_with_mean(get_mordred_desc(train_data['Solvent'], 'BertzCT'))\n",
        "solvent_3d_tr = fill_nan_with_mean(mordred_geometric(train_data['Solvent'], 'Asphericity'))\n",
        "solvent_4d_tr = fill_nan_with_mean(mordred_geometric(train_data['Solvent'], 'SpherocityIndex'))\n",
        "\n",
        "solute_mord1_tr = fill_nan_with_mean(get_mordred_desc(train_data['Solute'], 'SlogP_VSA1'))\n",
        "solute_mord2_tr = fill_nan_with_mean(get_mordred_desc(train_data['Solute'], 'SMR_VSA1'))\n",
        "solute_mord3_tr = fill_nan_with_mean(get_mordred_desc(train_data['Solute'], 'BalabanJ'))\n",
        "solute_mord4_tr = fill_nan_with_mean(get_mordred_desc(train_data['Solute'], 'BertzCT'))\n",
        "solute_3d_tr = fill_nan_with_mean(mordred_geometric(train_data['Solute'], 'Asphericity'))\n",
        "solute_4d_tr = fill_nan_with_mean(mordred_geometric(train_data['Solute'], 'SpherocityIndex'))\n",
        "\n",
        "solvent_mord1_te = fill_nan_with_mean(get_mordred_desc(test_data['Solvent'], 'SlogP_VSA1'))\n",
        "solvent_mord2_te = fill_nan_with_mean(get_mordred_desc(test_data['Solvent'], 'SMR_VSA1'))\n",
        "solvent_mord3_te = fill_nan_with_mean(get_mordred_desc(test_data['Solvent'], 'BalabanJ'))\n",
        "solvent_mord4_te = fill_nan_with_mean(get_mordred_desc(test_data['Solvent'], 'BertzCT'))\n",
        "solvent_3d_te = fill_nan_with_mean(mordred_geometric(test_data['Solvent'], 'Asphericity'))\n",
        "solvent_4d_te = fill_nan_with_mean(mordred_geometric(test_data['Solvent'], 'SpherocityIndex'))\n",
        "\n",
        "solute_mord1_te = fill_nan_with_mean(get_mordred_desc(test_data['Solute'], 'SlogP_VSA1'))\n",
        "solute_mord2_te = fill_nan_with_mean(get_mordred_desc(test_data['Solute'], 'SMR_VSA1'))\n",
        "solute_mord3_te = fill_nan_with_mean(get_mordred_desc(test_data['Solute'], 'BalabanJ'))\n",
        "solute_mord4_te = fill_nan_with_mean(get_mordred_desc(test_data['Solute'], 'BertzCT'))\n",
        "solute_3d_te = fill_nan_with_mean(mordred_geometric(test_data['Solute'], 'Asphericity'))\n",
        "solute_4d_te = fill_nan_with_mean(mordred_geometric(test_data['Solute'], 'SpherocityIndex'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RalXx1B-z1L6"
      },
      "source": [
        "### Choice of features explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "RCP0S-gzz5UZ"
      },
      "outputs": [],
      "source": [
        "# First I started by extracting information from mol_prop data provided.\n",
        "# Then, I also added more information from rdkit.\n",
        "# all of the features used has some sort of effect on solvation free energy,\n",
        "# so, it is important to get as much as feature as we can.\n",
        "# next, I also added morgan fingerprint data with nbits size 200\n",
        "# as we discussed in one of the psets, morgan fingerprint data can provide crucial informations for chemical compounds\n",
        "# each chemical feature of solvent and solute are represented as columns\n",
        "\n",
        "# I also tried adding mordred data\n",
        "# However, the data collection for mordred was too slow, so I skipped that part\n",
        "# since it would be inefficient."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yss40IY_dqEN"
      },
      "source": [
        "### 1.2 Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ixgSvHFhao0"
      },
      "source": [
        "Train a linear regression model and report a 5-fold cross-validated R^2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpkBJk5cdqEP",
        "outputId": "2c4c628d-3767-424c-b265-1da2f4c359f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validated R2 Scores: [0.79986372 0.82761602 0.79202493 0.8228516  0.83742855]\n",
            "Mean CV R2 Score: 0.8159569660696908\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Create a linear regression model\n",
        "model_linear = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model_linear.fit(X_train_1, y_tr)\n",
        "\n",
        "# Perform 5-fold cross-validation for R2 score\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_r2_scores = cross_val_score(model_linear, X_train_1, y_tr, cv=kf, scoring='r2')\n",
        "\n",
        "\n",
        "\n",
        "# Report the 5-fold cross-validated R2 score\n",
        "print(\"Cross-Validated R2 Scores:\", cv_r2_scores)\n",
        "print(\"Mean CV R2 Score:\", np.mean(cv_r2_scores))\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-laiNUcodqEP"
      },
      "source": [
        "### 1.3  MLP Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meAJkhi4hhuT"
      },
      "source": [
        "Train an MLP regression model and report a 5-fold cross-validated R^2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3ibqCdxdqER",
        "outputId": "641268c7-015a-47ea-e87a-eb0259c480bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5-fold Cross-Validated R^2 Scores: [0.95655047 0.95197437 0.96908507 0.95749992 0.95437971]\n",
            "Mean R^2 Score: 0.9578979047050243\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Assuming you have a NumPy array 'data_array' of shape (1569, 18) for input features\n",
        "# and a NumPy array 'target_array' of shape (1569, 1) for target values\n",
        "input_tensor = torch.tensor(X_train_fp, dtype=torch.float32)\n",
        "target_tensor = torch.tensor(y_tr, dtype=torch.float32)\n",
        "\n",
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, input_tensor, target_tensor):\n",
        "        self.input_data = input_tensor\n",
        "        self.target_data = target_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_data[idx], self.target_data[idx]\n",
        "\n",
        "# Create DataLoader\n",
        "batch_size = 32\n",
        "custom_dataset = CustomDataset(input_tensor, target_tensor)\n",
        "data_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(218, 128)  # Adjust input size to 18 for X_tr_1\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate model\n",
        "mlp_model = MLP()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100 # Set an appropriate number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_input, batch_target in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = mlp_model(batch_input)\n",
        "        loss = criterion(outputs, batch_target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Instantiate the regressor\n",
        "\n",
        "mlp_model = MLPRegressor(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "# Perform 5-fold cross-validation for R^2 score\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r2_scores = cross_val_score(mlp_model, input_tensor, target_tensor, scoring='r2', cv=kf)\n",
        "\n",
        "# Print the results\n",
        "print(\"5-fold Cross-Validated R^2 Scores:\", r2_scores)\n",
        "print(\"Mean R^2 Score:\", np.mean(r2_scores))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khdi-KB4p5Ei"
      },
      "source": [
        "Explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ibuxg_cpTzHf"
      },
      "outputs": [],
      "source": [
        "# running code for choosing hyperparameters took too long for mlp model\n",
        "# First I tried X_tr_1 (which is the feature set with chemical properties from rdkit) and got mean cv R^2 score of 0.935\n",
        "# then I updated my data by adding morgan fingerprint data, and this time I got mean R^2 score 0.956\n",
        "# I also tried adding more layers by changing it from 64 to 128 and got R^2 score of 0.953\n",
        "# tried changing num_epochs from 500 to 100 at 128 layer size and got 0.9579\n",
        "# tried num_epoch = 250 and layer size 128, got 0.9545\n",
        "\n",
        "# In conclusion, the best result that I obtained was using fingerprint data, num_epochs=100, and layer size (218, 128) and (128, 1)\n",
        "# I submitted my prediction to Kaggle and it passed the mlp baseline\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "npN-qSQDdqER"
      },
      "source": [
        "## Part 2: Machine Learning Competition and Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J34YVX-nkoJd"
      },
      "source": [
        "You can start a new notebook here to put all your models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "j3B9eYwVdqEd"
      },
      "outputs": [],
      "source": [
        "def save_submission(prediction, filename):\n",
        "    '''\n",
        "    Utility function to dump a submission file.\n",
        "\n",
        "    prediction (numpy.array): 1d numpy array contains your prediction\n",
        "    filename (str): file path to where you want to save the result\n",
        "    '''\n",
        "    sub = pd.DataFrame( {'index': list(range(len(prediction))), 'logK': prediction } )\n",
        "    sub.to_csv(filename, index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBUTkIfkjLBa"
      },
      "source": [
        "## 2.1 Random Forest approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGi47r1yjUyE",
        "outputId": "f12bc41a-452d-4c8d-ba4e-20afa3a1d384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation R^2 scores: [0.94743308 0.9604121  0.95741922 0.96445525 0.96482397]\n",
            "Mean CV R^2 Score: 0.95890872162364\n",
            "Standard Deviation of CV R^2 Score: 0.006354889676654997\n",
            "Training R^2 Score: 0.9949497785978473\n"
          ]
        }
      ],
      "source": [
        "# training RF\n",
        "\n",
        "# Define Random Forest model\n",
        "rf_model = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
        "\n",
        "#cross validation\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "cv_r2_scores = cross_val_score(rf_model, X_train_1, y_tr, cv=kf, scoring='r2')\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train_1, y_tr)\n",
        "\n",
        "# Predict on the training set for evaluation\n",
        "y_pred_train = rf_model.predict(X_train_1)\n",
        "\n",
        "# Calculate R^2 score on the training set\n",
        "train_r2_score = r2_score(y_tr, y_pred_train)\n",
        "\n",
        "# Print the cross-validation R^2 scores\n",
        "print(\"Cross-Validation R^2 scores:\", cv_r2_scores)\n",
        "\n",
        "# Print the mean and standard deviation of the cross-validation R^2 scores\n",
        "print(\"Mean CV R^2 Score:\", np.mean(cv_r2_scores))\n",
        "print(\"Standard Deviation of CV R^2 Score:\", np.std(cv_r2_scores))\n",
        "\n",
        "# Print the R^2 score on the training set\n",
        "print(\"Training R^2 Score:\", train_r2_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tds-4JzQnLZU"
      },
      "source": [
        "Why random forest explanation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "vQB40t88nP0I"
      },
      "outputs": [],
      "source": [
        "# The Random Forest algorithm presents a promising approach for this problem.\n",
        "# During the training phase, it generates numerous decision trees\n",
        "# Each tree is constructed using a random subset of the dataset and measures a random subset of features in each partition.\n",
        "# By constructing multiple trees with multiple subsets, it specifically learns interactions\n",
        "# When a feature interacts with another feature to influence the target variable, the ensemble of trees can capture these relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMIkOVmenR0E"
      },
      "source": [
        "## 2.2 Gradient Boosting approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQUt7TndngzJ",
        "outputId": "1194d7f2-788f-4758-fd77-c36b61d88074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation R^2 scores: [0.9534373  0.9710533  0.96750132 0.97107206 0.9769234 ]\n",
            "Mean CV R^2 Score: 0.9679974731496696\n",
            "Standard Deviation of CV R^2 Score: 0.007882996660027905\n",
            "Training R^2 Score: 0.9940615126747256\n"
          ]
        }
      ],
      "source": [
        "# Gradient Boosting\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "gb_model = GradientBoostingRegressor(n_estimators=1000, random_state=42)\n",
        "\n",
        "\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "cv_r2_scores = cross_val_score(gb_model, X_train_1, y_tr, cv=kf, scoring='r2')\n",
        "\n",
        "\n",
        "gb_model.fit(X_train_1, y_tr)\n",
        "y_pred_train = gb_model.predict(X_train_1)\n",
        "\n",
        "\n",
        "train_r2_score = r2_score(y_tr, y_pred_train)\n",
        "\n",
        "\n",
        "print(\"Cross-Validation R^2 scores:\", cv_r2_scores)\n",
        "print(\"Mean CV R^2 Score:\", np.mean(cv_r2_scores))\n",
        "print(\"Standard Deviation of CV R^2 Score:\", np.std(cv_r2_scores))\n",
        "print(\"Training R^2 Score:\", train_r2_score)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcDn9_X_pOdk"
      },
      "source": [
        "Why Gradient Boosting explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "-s1zaxJUpRUI"
      },
      "outputs": [],
      "source": [
        "# Gradient Boosting is another suitable choice for this problem.\n",
        "# In GB model, the process starts with simple decision tree, and newly added tree tries to explain the error left behind the previous tree.\n",
        "# when feature interacts with another feature to influence the target variable, the ensemble of trees can learn these relationships.\n",
        "# By minimazing loss gradient during training, it learns interactions and improve the accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAV3P93jxBXK"
      },
      "source": [
        "## 2.1.2 Random Forest with FP+previous chemical feature set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhfPwq8-3tRo",
        "outputId": "659ddc16-8685-40dc-e701-f2de98aa9f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation R^2 scores: [0.92082739 0.9575236 ]\n",
            "Mean CV R^2 Score: 0.9391754962335037\n",
            "Standard Deviation of CV R^2 Score: 0.018348104812371535\n",
            "Training R^2 Score: 0.9944062683221588\n"
          ]
        }
      ],
      "source": [
        "# training RF\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Assuming X_train and y_train are your features and target variable respectively\n",
        "# Assuming you have imported your data using data loader and preprocessed it\n",
        "\n",
        "# Define your Random Forest model\n",
        "rf_model_fp = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 2\n",
        "\n",
        "# Initialize cross-validation\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_r2_scores = cross_val_score(rf_model_fp, X_train_fp, y_tr, cv=kf, scoring='r2')\n",
        "\n",
        "# Train the model on the whole dataset\n",
        "rf_model_fp.fit(X_train_fp, y_tr)\n",
        "\n",
        "# Predict on the training set for evaluation\n",
        "y_pred_train = rf_model_fp.predict(X_train_fp)\n",
        "\n",
        "# Calculate R^2 score on the training set\n",
        "train_r2_score = r2_score(y_tr, y_pred_train)\n",
        "\n",
        "# Print the cross-validation R^2 scores\n",
        "print(\"Cross-Validation R^2 scores:\", cv_r2_scores)\n",
        "\n",
        "# Print the mean and standard deviation of the cross-validation R^2 scores\n",
        "print(\"Mean CV R^2 Score:\", np.mean(cv_r2_scores))\n",
        "print(\"Standard Deviation of CV R^2 Score:\", np.std(cv_r2_scores))\n",
        "\n",
        "# Print the R^2 score on the training set\n",
        "print(\"Training R^2 Score:\", train_r2_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "YiQyq8hX_dVd"
      },
      "outputs": [],
      "source": [
        "# I tried using combination of fingerprint data and previous chemical features from rdkit for random forest.\n",
        "# I also tried different n_estimators (100, 500, 1000), and they were 0.940 which is lower than the previous RF model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha4XvmHg8BEo"
      },
      "source": [
        "## 2.2.2 Optimized Gradient Boosting with FP+previous chemical feature set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YME8HCbZ8GlZ",
        "outputId": "8e3b4a22-7ddc-420b-a133-9487a0bda0c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation R^2 scores: [0.96468532 0.97728473 0.97404375 0.97637981 0.97305431]\n",
            "Mean CV R^2 Score: 0.9730895828551237\n",
            "Standard Deviation of CV R^2 Score: 0.004471426268787465\n",
            "Training R^2 Score: 0.9961560975248541\n"
          ]
        }
      ],
      "source": [
        "# Gradient Boosting\n",
        "# Define your Gradient Boosting model\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "gb_model = GradientBoostingRegressor(n_estimators=1000, random_state=42)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "\n",
        "# Initialize cross-validation\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_r2_scores = cross_val_score(gb_model, X_train_fp, y_tr, cv=kf, scoring='r2')\n",
        "\n",
        "# Train the model on the whole dataset\n",
        "gb_model.fit(X_train_fp, y_tr)\n",
        "\n",
        "# Predict on the training set for evaluation\n",
        "y_pred_train = gb_model.predict(X_train_fp)\n",
        "\n",
        "# Calculate R^2 score on the training set\n",
        "train_r2_score = r2_score(y_tr, y_pred_train)\n",
        "\n",
        "# Print the cross-validation R^2 scores\n",
        "print(\"Cross-Validation R^2 scores:\", cv_r2_scores)\n",
        "\n",
        "# Print the mean and standard deviation of the cross-validation R^2 scores\n",
        "print(\"Mean CV R^2 Score:\", np.mean(cv_r2_scores))\n",
        "print(\"Standard Deviation of CV R^2 Score:\", np.std(cv_r2_scores))\n",
        "\n",
        "# Print the R^2 score on the training set\n",
        "print(\"Training R^2 Score:\", train_r2_score)\n",
        "\n",
        "\n",
        "#gradient booster per molecule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "CF4-5Jo49QI7"
      },
      "outputs": [],
      "source": [
        "# I also did the same thing for gradient boosting model.\n",
        "# for num_estimators, 1000 showed the highest R^2 score, which is 0.973."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MQVdkBJNAnDG"
      },
      "source": [
        "## 2.4 Graph based approach \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBjq2TyHA1pC"
      },
      "source": [
        "A SMILES to graph conversion function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "quIQlzy7A6ES"
      },
      "outputs": [],
      "source": [
        "def smiles2graph(smiles):\n",
        "    '''\n",
        "    Transform smiles into a list of atomic numbers and an edge array\n",
        "\n",
        "    Args:\n",
        "        smiles (str): SMILES strings\n",
        "\n",
        "    Returns:\n",
        "        z(np.array), A (np.array): list of atomic numbers, edge array\n",
        "    '''\n",
        "\n",
        "    mol = Chem.MolFromSmiles( smiles ) # no hydrogen\n",
        "    z = np.array( [atom.GetAtomicNum() for atom in mol.GetAtoms()] )\n",
        "    A = np.stack(Chem.GetAdjacencyMatrix(mol)).nonzero()\n",
        "\n",
        "    return z, A\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nU11druC2tO",
        "outputId": "3cb7c174-7982-4fa4-92d5-9dc48fd8d822"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-62-80beb0e00bff>:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  solvent_tr_Edge_list.append(torch.LongTensor(a))\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:36] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n",
            "[04:41:37] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        }
      ],
      "source": [
        "solvent_tr_AtomicNum_list = []\n",
        "solvent_tr_Edge_list = []\n",
        "solvent_tr_Natom_list = []\n",
        "\n",
        "solute_tr_AtomicNum_list = []\n",
        "solute_tr_Edge_list = []\n",
        "solute_tr_Natom_list = []\n",
        "\n",
        "solute_te_AtomicNum_list = []\n",
        "solute_te_Edge_list = []\n",
        "solute_te_Natom_list = []\n",
        "\n",
        "solvent_te_AtomicNum_list = []\n",
        "solvent_te_Edge_list = []\n",
        "solvent_te_Natom_list = []\n",
        "\n",
        "\n",
        "\n",
        "for smiles in train_data['Solvent']:\n",
        "        z, a = smiles2graph(smiles)\n",
        "\n",
        "        mol = Chem.MolFromSmiles( smiles )\n",
        "        solvent_tr_AtomicNum_list.append(torch.LongTensor(z))\n",
        "        solvent_tr_Edge_list.append(torch.LongTensor(a))\n",
        "        solvent_tr_Natom_list.append(len(z))\n",
        "\n",
        "for smiles in train_data['Solute']:\n",
        "        z, a = smiles2graph(smiles)\n",
        "        mol = Chem.MolFromSmiles( smiles )\n",
        "        solute_tr_AtomicNum_list.append(torch.LongTensor(z))\n",
        "        solute_tr_Edge_list.append(torch.LongTensor(a))\n",
        "        solute_tr_Natom_list.append(len(z))\n",
        "\n",
        "for smiles in test_data['Solvent']:\n",
        "        z, a = smiles2graph(smiles)\n",
        "        mol = Chem.MolFromSmiles( smiles )\n",
        "        solute_te_AtomicNum_list.append(torch.LongTensor(z))\n",
        "        solute_te_Edge_list.append(torch.LongTensor(a))\n",
        "        solute_te_Natom_list.append(len(z))\n",
        "\n",
        "for smiles in test_data['Solute']:\n",
        "        z, a = smiles2graph(smiles)\n",
        "        mol = Chem.MolFromSmiles( smiles )\n",
        "        solute_te_AtomicNum_list.append(torch.LongTensor(z))\n",
        "        solute_te_Edge_list.append(torch.LongTensor(a))\n",
        "        solute_te_Natom_list.append(len(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "cTnXZUBTM_Gn"
      },
      "outputs": [],
      "source": [
        "class GraphDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,\n",
        "                 AtomicNum_list,\n",
        "                 Edge_list,\n",
        "                 Natom_list,\n",
        "                 y_list=None):\n",
        "\n",
        "        '''\n",
        "        GraphDataset object\n",
        "\n",
        "        Args:\n",
        "            z_list (list of torch.LongTensor)\n",
        "            a_list (list of torch.LongTensor)\n",
        "            N_list (list of int)\n",
        "            y_list (list of torch.FloatTensor), optional\n",
        "                Properties to predict. Default is None.\n",
        "\n",
        "        '''\n",
        "        self.AtomicNum_list = AtomicNum_list  # atomic number\n",
        "        self.Edge_list = Edge_list  # edge list\n",
        "        self.Natom_list = Natom_list  # Number of atoms\n",
        "        self.y_list = y_list  # properties to predict\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Natom_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "\n",
        "\n",
        "        AtomicNum = torch.LongTensor(self.AtomicNum_list[idx])\n",
        "        Edge = torch.LongTensor(self.Edge_list[idx])\n",
        "        Natom = self.Natom_list[idx]\n",
        "\n",
        "        if self.y_list is not None:\n",
        "            y = self.y_list[idx]\n",
        "            return AtomicNum, Edge, Natom, y\n",
        "        else:\n",
        "            return AtomicNum, Edge, Natom\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDOplMpqNyyc",
        "outputId": "23d0dbfa-518c-4300-995c-231ab12a4ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([4.8300]), tensor([2.7600]), tensor([3.1340]), tensor([3.4400]), tensor([2.5400]), tensor([2.3170]), tensor([2.4760]), tensor([2.4620]), tensor([1.3500]), tensor([-0.2900]), tensor([3.9470]), tensor([3.1800]), tensor([3.3500]), tensor([1.5400]), tensor([2.7010]), tensor([3.7200]), tensor([2.9880]), tensor([4.2110]), tensor([2.5800]), tensor([2.8800]), tensor([3.5560]), tensor([4.7000]), tensor([2.5570]), tensor([2.8280]), tensor([2.9400]), tensor([2.9900]), tensor([1.7960]), tensor([4.9730]), tensor([2.1280]), tensor([3.6700]), tensor([-0.3800]), tensor([3.5000]), tensor([4.7700]), tensor([-1.0700]), tensor([2.8720]), tensor([3.6400]), tensor([4.1390]), tensor([5.1000]), tensor([2.1600]), tensor([2.8680]), tensor([1.5500]), tensor([2.5290]), tensor([3.0600]), tensor([3.1740]), tensor([2.5730]), tensor([3.8600]), tensor([4.6600]), tensor([3.1520]), tensor([4.6190]), tensor([-0.8800]), tensor([2.7100]), tensor([3.6700]), tensor([3.2420]), tensor([5.2300]), tensor([1.5400]), tensor([3.4000]), tensor([2.2100]), tensor([1.4200]), tensor([2.1950]), tensor([3.1020]), tensor([3.3600]), tensor([-0.1420]), tensor([2.3800]), tensor([3.0740]), tensor([2.3700]), tensor([4.0600]), tensor([1.8100]), tensor([0.4100]), tensor([2.1560]), tensor([0.5700]), tensor([2.1400]), tensor([6.3000]), tensor([2.5500]), tensor([-0.3730]), tensor([3.7300]), tensor([-1.6680]), tensor([4.8970]), tensor([3.4000]), tensor([1.4000]), tensor([2.8420]), tensor([2.7700]), tensor([4.6700]), tensor([2.2500]), tensor([3.4500]), tensor([4.5900]), tensor([3.1500]), tensor([3.8300]), tensor([2.2640]), tensor([2.8430]), tensor([3.1900]), tensor([0.2270]), tensor([3.6500]), tensor([2.4470]), tensor([2.8400]), tensor([4.1900]), tensor([3.6400]), tensor([2.4900]), tensor([2.3700]), tensor([2.6700]), tensor([-0.1250]), tensor([2.3910]), tensor([3.4730]), tensor([4.5700]), tensor([1.7500]), tensor([2.8230]), tensor([4.9440]), tensor([3.1470]), tensor([3.6500]), tensor([3.3350]), tensor([1.8180]), tensor([3.0300]), tensor([4.2100]), tensor([4.7500]), tensor([2.9600]), tensor([1.5400]), tensor([0.3000]), tensor([5.1500]), tensor([-0.2200]), tensor([3.6100]), tensor([3.5200]), tensor([3.2500]), tensor([2.2110]), tensor([0.4500]), tensor([0.7880]), tensor([4.5280]), tensor([2.5330]), tensor([3.4150]), tensor([6.1970]), tensor([3.8800]), tensor([2.6070]), tensor([2.4300]), tensor([4.5100]), tensor([-1.2500]), tensor([3.8900]), tensor([-0.3900]), tensor([3.1060]), tensor([3.3800]), tensor([2.1900]), tensor([1.7600]), tensor([3.3500]), tensor([4.4900]), tensor([2.1600]), tensor([-0.4000]), tensor([-1.0600]), tensor([3.0180]), tensor([2.9900]), tensor([1.0400]), tensor([2.9500]), tensor([4.6300]), tensor([3.4600]), tensor([2.1000]), tensor([3.5530]), tensor([2.5860]), tensor([3.4400]), tensor([2.6000]), tensor([0.5760]), tensor([1.6430]), tensor([2.6000]), tensor([3.1900]), tensor([2.5100]), tensor([2.6010]), tensor([0.4450]), tensor([4.2100]), tensor([11.2100]), tensor([3.2600]), tensor([3.3640]), tensor([-0.6240]), tensor([0.4400]), tensor([3.1300]), tensor([3.2180]), tensor([0.9300]), tensor([1.5700]), tensor([3.4240]), tensor([3.4420]), tensor([3.4200]), tensor([3.3260]), tensor([3.9242]), tensor([4.4500]), tensor([3.8080]), tensor([2.7300]), tensor([6.4200]), tensor([1.1100]), tensor([4.8700]), tensor([2.1200]), tensor([3.2900]), tensor([5.9500]), tensor([2.6600]), tensor([2.5850]), tensor([2.6900]), tensor([-0.1900]), tensor([0.3700]), tensor([4.4500]), tensor([4.6200]), tensor([4.0900]), tensor([3.0400]), tensor([5.2900]), tensor([5.4800]), tensor([-0.7100]), tensor([3.6600]), tensor([3.5400]), tensor([2.9990]), tensor([1.5500]), tensor([3.8000]), tensor([-0.7100]), tensor([3.0100]), tensor([4.4100]), tensor([4.3070]), tensor([2.7900]), tensor([-1.4500]), tensor([0.6600]), tensor([4.3363]), tensor([3.6700]), tensor([4.7400]), tensor([3.8900]), tensor([1.7600]), tensor([0.4600]), tensor([1.]), tensor([0.2600]), tensor([1.0500]), tensor([3.9160]), tensor([1.9900]), tensor([2.4000]), tensor([3.5710]), tensor([1.4410]), tensor([2.2900]), tensor([3.4770]), tensor([3.]), tensor([0.6300]), tensor([3.0860]), tensor([4.0100]), tensor([3.5100]), tensor([2.8300]), tensor([4.1000]), tensor([1.7290]), tensor([2.2900]), tensor([-0.1200]), tensor([3.4600]), tensor([1.7960]), tensor([8.7500]), tensor([2.1660]), tensor([2.5500]), tensor([3.6500]), tensor([-1.3400]), tensor([8.1400]), tensor([3.0700]), tensor([2.6100]), tensor([3.3900]), tensor([2.6800]), tensor([2.5900]), tensor([6.6200]), tensor([3.0950]), tensor([2.9200]), tensor([3.7200]), tensor([3.5910]), tensor([2.4300]), tensor([2.4500]), tensor([3.1090]), tensor([2.3900]), tensor([3.2100]), tensor([1.7400]), tensor([1.3920]), tensor([0.9700]), tensor([3.1480]), tensor([4.4700]), tensor([3.4200]), tensor([4.3100]), tensor([3.8400]), tensor([1.0960]), tensor([3.1000]), tensor([3.4800]), tensor([3.3000]), tensor([2.8120]), tensor([2.6000]), tensor([4.3250]), tensor([2.7550]), tensor([3.4200]), tensor([2.6480]), tensor([2.3710]), tensor([-1.5450]), tensor([-0.6100]), tensor([-0.2770]), tensor([2.8600]), tensor([1.9400]), tensor([4.2220]), tensor([2.4100]), tensor([2.1400]), tensor([2.9650]), tensor([4.2300]), tensor([-0.6600]), tensor([5.5700]), tensor([3.5200]), tensor([3.2000]), tensor([7.1300]), tensor([2.4000]), tensor([2.7300]), tensor([-1.2800]), tensor([8.0900]), tensor([4.2600]), tensor([5.8300]), tensor([-0.6320]), tensor([0.8810]), tensor([3.5060]), tensor([3.9020]), tensor([2.3300]), tensor([2.1300]), tensor([3.0960]), tensor([-0.2200]), tensor([3.0100]), tensor([-0.2740]), tensor([0.4270]), tensor([3.2300]), tensor([2.9460]), tensor([3.2400]), tensor([3.1800]), tensor([1.6200]), tensor([3.2460]), tensor([2.7600]), tensor([2.5900]), tensor([1.7700]), tensor([-0.1400]), tensor([3.8100]), tensor([-1.1300]), tensor([2.6900]), tensor([4.0800]), tensor([-0.1800]), tensor([6.9700]), tensor([-0.1400]), tensor([2.6900]), tensor([1.6800]), tensor([3.9400]), tensor([3.0550]), tensor([3.4530]), tensor([3.8380]), tensor([1.5200]), tensor([3.6770]), tensor([1.0700]), tensor([2.2700]), tensor([2.9800]), tensor([-0.9500]), tensor([-0.1770]), tensor([8.1300]), tensor([2.4400]), tensor([2.7600]), tensor([1.5900]), tensor([3.3700]), tensor([2.6600]), tensor([1.7700]), tensor([3.9410]), tensor([1.4200]), tensor([4.9470]), tensor([0.5600]), tensor([0.0410]), tensor([2.1980]), tensor([1.4500]), tensor([2.8700]), tensor([3.4760]), tensor([5.2340]), tensor([2.5590]), tensor([-0.7900]), tensor([1.7800]), tensor([2.7270]), tensor([3.2100]), tensor([4.2200]), tensor([2.6540]), tensor([3.0700]), tensor([1.2390]), tensor([3.5640]), tensor([2.3800]), tensor([2.7700]), tensor([3.1800]), tensor([3.6610]), tensor([-1.0910]), tensor([2.6700]), tensor([3.6500]), tensor([4.9060]), tensor([0.4000]), tensor([1.3400]), tensor([4.1400]), tensor([0.9700]), tensor([2.8610]), tensor([3.3000]), tensor([2.3600]), tensor([-1.1870]), tensor([2.1480]), tensor([-1.2760]), tensor([3.4300]), tensor([3.1500]), tensor([-1.3640]), tensor([2.8700]), tensor([3.1860]), tensor([3.1200]), tensor([-1.5940]), tensor([2.2400]), tensor([2.6000]), tensor([3.3500]), tensor([2.0190]), tensor([-0.5600]), tensor([1.4900]), tensor([1.4950]), tensor([2.9600]), tensor([3.5900]), tensor([-1.7400]), tensor([1.0900]), tensor([3.8200]), tensor([1.7500]), tensor([3.6400]), tensor([-1.8260]), tensor([3.0400]), tensor([2.6620]), tensor([0.8200]), tensor([3.4240]), tensor([6.0600]), tensor([2.5500]), tensor([1.3100]), tensor([0.6700]), tensor([3.6500]), tensor([1.2330]), tensor([5.3800]), tensor([2.9500]), tensor([5.5000]), tensor([2.9900]), tensor([4.6400]), tensor([3.5320]), tensor([2.0130]), tensor([2.2080]), tensor([4.0700]), tensor([3.0300]), tensor([3.5470]), tensor([1.1150]), tensor([0.1180]), tensor([1.3700]), tensor([2.4290]), tensor([3.3870]), tensor([4.1600]), tensor([2.5810]), tensor([2.1000]), tensor([0.5470]), tensor([2.7060]), tensor([2.7400]), tensor([-0.8840]), tensor([3.1730]), tensor([1.2800]), tensor([3.4400]), tensor([3.9200]), tensor([0.3700]), tensor([4.0350]), tensor([3.5150]), tensor([2.8500]), tensor([2.5990]), tensor([3.8100]), tensor([2.9500]), tensor([1.9630]), tensor([1.3300]), tensor([2.0100]), tensor([3.4400]), tensor([1.7900]), tensor([2.4600]), tensor([0.8800]), tensor([-0.3300]), tensor([4.1480]), tensor([3.9260]), tensor([3.9000]), tensor([4.1500]), tensor([5.1400]), tensor([2.9840]), tensor([3.7200]), tensor([2.9770]), tensor([-1.1100]), tensor([2.0590]), tensor([3.1300]), tensor([4.0300]), tensor([-0.3440]), tensor([4.3660]), tensor([1.8340]), tensor([3.5500]), tensor([4.1500]), tensor([3.0340]), tensor([2.6600]), tensor([2.5500]), tensor([-0.3790]), tensor([1.0400]), tensor([-1.0600]), tensor([2.1200]), tensor([-1.2900]), tensor([3.9120]), tensor([0.2300]), tensor([4.8490]), tensor([-1.6060]), tensor([3.2670]), tensor([1.1630]), tensor([4.6200]), tensor([3.6500]), tensor([4.4700]), tensor([-1.0310]), tensor([3.1790]), tensor([2.5720]), tensor([1.0300]), tensor([3.5440]), tensor([3.2400]), tensor([3.6440]), tensor([3.8410]), tensor([2.8200]), tensor([2.7401]), tensor([3.0810]), tensor([2.5800]), tensor([2.7693]), tensor([2.3500]), tensor([2.6800]), tensor([3.5540]), tensor([3.1810]), tensor([0.9590]), tensor([2.4850]), tensor([4.4700]), tensor([-0.8200]), tensor([2.4900]), tensor([1.8200]), tensor([3.7800]), tensor([2.7000]), tensor([-1.0700]), tensor([1.1370]), tensor([3.6800]), tensor([2.8930]), tensor([2.4800]), tensor([2.0700]), tensor([3.8800]), tensor([2.2200]), tensor([3.3000]), tensor([6.2700]), tensor([4.2000]), tensor([2.8930]), tensor([4.1600]), tensor([-0.6500]), tensor([-0.6800]), tensor([2.4430]), tensor([1.5100]), tensor([-1.2050]), tensor([3.2700]), tensor([1.5510]), tensor([6.5700]), tensor([2.3030]), tensor([2.2900]), tensor([3.3100]), tensor([2.8700]), tensor([3.3090]), tensor([2.5560]), tensor([2.9500]), tensor([-1.1990]), tensor([2.6510]), tensor([0.6580]), tensor([-1.0700]), tensor([-0.2990]), tensor([2.1900]), tensor([5.7500]), tensor([2.8100]), tensor([3.8600]), tensor([3.6900]), tensor([2.8300]), tensor([-0.6100]), tensor([3.5850]), tensor([1.5100]), tensor([2.1100]), tensor([1.4590]), tensor([2.6000]), tensor([2.7700]), tensor([2.0560]), tensor([2.2200]), tensor([3.7380]), tensor([3.3750]), tensor([3.6170]), tensor([4.2000]), tensor([0.7900]), tensor([1.8060]), tensor([3.3390]), tensor([2.2600]), tensor([3.1200]), tensor([3.2530]), tensor([-0.4710]), tensor([2.7000]), tensor([1.5200]), tensor([2.4390]), tensor([1.9500]), tensor([2.8000]), tensor([1.9200]), tensor([3.0700]), tensor([2.6100]), tensor([-0.3230]), tensor([1.7220]), tensor([2.7600]), tensor([1.6500]), tensor([2.7730]), tensor([4.2200]), tensor([2.0100]), tensor([1.6400]), tensor([3.9810]), tensor([-0.7100]), tensor([-0.9240]), tensor([2.6230]), tensor([2.8900]), tensor([-0.3880]), tensor([3.0200]), tensor([3.9120]), tensor([1.3500]), tensor([2.4900]), tensor([3.8220]), tensor([-0.8700]), tensor([3.8530]), tensor([1.8800]), tensor([3.9700]), tensor([0.5540]), tensor([3.1000]), tensor([0.0760]), tensor([3.1300]), tensor([4.3400]), tensor([4.4050]), tensor([2.3500]), tensor([5.1200]), tensor([-0.2800]), tensor([3.2900]), tensor([2.9970]), tensor([2.8540]), tensor([-1.1200]), tensor([3.7200]), tensor([0.9700]), tensor([4.4300]), tensor([3.4840]), tensor([3.2130]), tensor([2.0200]), tensor([1.3240]), tensor([3.7700]), tensor([6.8300]), tensor([4.0050]), tensor([2.3300]), tensor([1.6700]), tensor([2.4400]), tensor([3.2720]), tensor([-0.6030]), tensor([1.4700]), tensor([3.0250]), tensor([3.0770]), tensor([-0.6270]), tensor([2.4700]), tensor([-1.4900]), tensor([2.5500]), tensor([5.1200]), tensor([4.3200]), tensor([2.2600]), tensor([1.5500]), tensor([2.4720]), tensor([0.4200]), tensor([0.8000]), tensor([3.0300]), tensor([3.6950]), tensor([2.7220]), tensor([2.2600]), tensor([2.7900]), tensor([0.4400]), tensor([2.3800]), tensor([2.9800]), tensor([-0.7400]), tensor([3.1000]), tensor([1.4500]), tensor([-0.9300]), tensor([3.6440]), tensor([1.7100]), tensor([-0.5500]), tensor([2.2400]), tensor([3.2600]), tensor([3.6780]), tensor([0.4500]), tensor([2.4134]), tensor([1.2410]), tensor([3.3900]), tensor([6.0400]), tensor([2.7300]), tensor([2.6600]), tensor([1.8600]), tensor([3.2600]), tensor([3.8800]), tensor([4.2210]), tensor([3.5580]), tensor([2.6890]), tensor([3.7900]), tensor([3.5300]), tensor([5.7700]), tensor([4.3300]), tensor([1.9600]), tensor([2.7120]), tensor([-1.8100]), tensor([4.5950]), tensor([4.2500]), tensor([4.7400]), tensor([0.9500]), tensor([6.2000]), tensor([1.7900]), tensor([0.4000]), tensor([3.2987]), tensor([-0.7500]), tensor([3.8300]), tensor([0.9500]), tensor([2.8900]), tensor([4.5200]), tensor([2.6500]), tensor([2.3300]), tensor([1.9650]), tensor([3.2340]), tensor([2.6500]), tensor([-1.4300]), tensor([3.1700]), tensor([3.2830]), tensor([3.8700]), tensor([-0.6060]), tensor([3.4660]), tensor([5.1240]), tensor([9.2600]), tensor([2.7100]), tensor([-0.3100]), tensor([3.8300]), tensor([3.9100]), tensor([4.8450]), tensor([-0.8200]), tensor([2.1460]), tensor([-0.3450]), tensor([-0.5130]), tensor([0.7200]), tensor([3.0310]), tensor([-0.5500]), tensor([3.8300]), tensor([0.3800]), tensor([3.8198]), tensor([-0.6720]), tensor([4.2700]), tensor([-1.6500]), tensor([2.5700]), tensor([3.9500]), tensor([3.7900]), tensor([2.7800]), tensor([2.7400]), tensor([2.8600]), tensor([-0.2100]), tensor([2.5900]), tensor([1.5500]), tensor([6.2500]), tensor([2.4030]), tensor([10.9300]), tensor([3.1800]), tensor([2.5650]), tensor([1.9700]), tensor([2.0710]), tensor([2.9980]), tensor([1.6100]), tensor([3.1600]), tensor([3.6700]), tensor([3.1710]), tensor([4.2000]), tensor([3.2600]), tensor([2.5200]), tensor([2.3400]), tensor([1.4910]), tensor([5.5600]), tensor([2.5300]), tensor([1.6690]), tensor([3.0490]), tensor([1.7600]), tensor([3.6320]), tensor([0.3800]), tensor([2.5480]), tensor([3.3240]), tensor([1.3300]), tensor([-0.2740]), tensor([2.2290]), tensor([-0.5700]), tensor([-0.3440]), tensor([-0.7700]), tensor([2.7900]), tensor([2.9400]), tensor([4.5300]), tensor([4.6600]), tensor([1.4700]), tensor([3.1570]), tensor([2.9700]), tensor([3.6900]), tensor([-0.1700]), tensor([1.3700]), tensor([0.3780]), tensor([-0.5210]), tensor([3.9000]), tensor([2.6300]), tensor([2.8400]), tensor([2.3300]), tensor([0.4700]), tensor([3.0370]), tensor([1.5400]), tensor([1.4910]), tensor([-0.5840]), tensor([2.8430]), tensor([4.9200]), tensor([4.7700]), tensor([1.5100]), tensor([3.9600]), tensor([2.5400]), tensor([3.5010]), tensor([2.9233]), tensor([4.1360]), tensor([1.2240]), tensor([4.2800]), tensor([1.7520]), tensor([4.4600]), tensor([2.9100]), tensor([1.9500]), tensor([0.9220]), tensor([2.5200]), tensor([1.4600]), tensor([2.3700]), tensor([2.6400]), tensor([1.9200]), tensor([0.5800]), tensor([3.9500]), tensor([2.8200]), tensor([3.2380]), tensor([4.1700]), tensor([1.9900]), tensor([2.3673]), tensor([7.8100]), tensor([4.0900]), tensor([2.3200]), tensor([1.4500]), tensor([3.8521]), tensor([2.5700]), tensor([-0.7990]), tensor([4.0070]), tensor([2.6900]), tensor([1.9700]), tensor([4.6420]), tensor([3.7410]), tensor([1.5300]), tensor([0.7500]), tensor([1.3200]), tensor([9.4000]), tensor([3.6700]), tensor([2.0290]), tensor([3.1790]), tensor([2.1000]), tensor([2.3400]), tensor([2.9700]), tensor([2.6000]), tensor([2.3270]), tensor([0.3780]), tensor([3.5020]), tensor([3.2200]), tensor([3.1310]), tensor([0.2150]), tensor([2.7800]), tensor([4.0300]), tensor([0.6000]), tensor([2.8770]), tensor([3.2790]), tensor([2.6700]), tensor([2.4800]), tensor([3.9900]), tensor([3.0350]), tensor([2.3500]), tensor([1.8800]), tensor([3.6800]), tensor([-0.8100]), tensor([-0.2640]), tensor([3.0200]), tensor([2.6260]), tensor([1.5860]), tensor([1.4500]), tensor([2.0900]), tensor([0.4400]), tensor([1.5900]), tensor([1.7810]), tensor([3.5700]), tensor([-0.5700]), tensor([-0.6200]), tensor([3.3620]), tensor([3.3800]), tensor([3.5410]), tensor([3.4100]), tensor([3.0620]), tensor([2.8700]), tensor([2.0540]), tensor([2.5440]), tensor([5.1180]), tensor([0.5400]), tensor([5.6170]), tensor([3.0400]), tensor([2.5100]), tensor([3.5700]), tensor([3.5110]), tensor([2.4310]), tensor([2.8540]), tensor([1.6500]), tensor([3.6780]), tensor([3.6070]), tensor([-1.6300]), tensor([2.8800]), tensor([8.0100]), tensor([1.3200]), tensor([0.9700]), tensor([3.2900]), tensor([4.0710]), tensor([2.7380]), tensor([4.1050]), tensor([3.4300]), tensor([5.9060]), tensor([0.4920]), tensor([2.5100]), tensor([4.0840]), tensor([3.4000]), tensor([0.9700]), tensor([4.4700]), tensor([2.3900]), tensor([4.3230]), tensor([1.4900]), tensor([-0.8810]), tensor([0.6300]), tensor([4.7200]), tensor([2.7020]), tensor([0.4200]), tensor([2.0400]), tensor([1.2080]), tensor([4.0400]), tensor([4.9180]), tensor([2.8200]), tensor([4.2330]), tensor([4.0830]), tensor([3.1440]), tensor([3.1400]), tensor([4.1800]), tensor([1.9800]), tensor([3.4746]), tensor([2.2900]), tensor([4.3900]), tensor([3.8200]), tensor([2.8960]), tensor([-1.1000]), tensor([2.0100]), tensor([3.8110]), tensor([3.0500]), tensor([-0.1420]), tensor([4.4500]), tensor([3.5500]), tensor([0.3200]), tensor([3.5490]), tensor([2.3760]), tensor([3.7760]), tensor([-1.1700]), tensor([3.2440]), tensor([2.0200]), tensor([2.4980]), tensor([3.2700]), tensor([2.7000]), tensor([4.2500]), tensor([1.3900]), tensor([4.3600]), tensor([2.1100]), tensor([3.6130]), tensor([3.0050]), tensor([1.8100]), tensor([-1.6300]), tensor([4.1300]), tensor([1.6000]), tensor([3.9720]), tensor([0.2950]), tensor([3.9200]), tensor([2.2900]), tensor([1.9100]), tensor([3.8000]), tensor([1.9800]), tensor([4.5300]), tensor([0.4500]), tensor([3.8610]), tensor([2.9470]), tensor([0.4400]), tensor([3.1800]), tensor([1.5600]), tensor([0.2690]), tensor([2.8450]), tensor([3.6030]), tensor([3.8700]), tensor([0.0200]), tensor([2.6020]), tensor([3.3100]), tensor([2.5700]), tensor([2.0300]), tensor([3.5000]), tensor([1.3300]), tensor([3.8430]), tensor([4.1400]), tensor([2.4720]), tensor([3.2100]), tensor([3.7030]), tensor([2.8060]), tensor([3.0420]), tensor([1.1400]), tensor([3.0300]), tensor([4.2800]), tensor([5.4360]), tensor([2.5000]), tensor([4.6600]), tensor([3.8270]), tensor([-0.7800]), tensor([-1.0670]), tensor([2.4850]), tensor([3.7480]), tensor([4.4500]), tensor([2.8420]), tensor([3.0110]), tensor([5.8900]), tensor([0.5900]), tensor([-1.5420]), tensor([5.7100]), tensor([2.2020]), tensor([3.1200]), tensor([1.7100]), tensor([0.0710]), tensor([1.2860]), tensor([-0.6000]), tensor([3.7151]), tensor([3.9430]), tensor([4.4500]), tensor([2.5700]), tensor([2.6590]), tensor([2.4200]), tensor([-0.7200]), tensor([2.3100]), tensor([3.2000]), tensor([3.0300]), tensor([3.0570]), tensor([2.3500]), tensor([2.0970]), tensor([2.9220]), tensor([3.5700]), tensor([2.5020]), tensor([2.4800]), tensor([0.8900]), tensor([3.6500]), tensor([6.0200]), tensor([4.1340]), tensor([1.6200]), tensor([3.8100]), tensor([-0.3610]), tensor([0.4300]), tensor([4.6000]), tensor([3.6790]), tensor([-0.3640]), tensor([3.0600]), tensor([-1.3200]), tensor([3.4493]), tensor([3.0810]), tensor([3.2200]), tensor([0.4400]), tensor([3.9400]), tensor([1.3140]), tensor([2.0410]), tensor([2.9700]), tensor([-0.5200]), tensor([3.8000]), tensor([1.4570]), tensor([1.8200]), tensor([0.7300]), tensor([1.1300]), tensor([-0.0120]), tensor([2.4800]), tensor([4.1900]), tensor([4.8400]), tensor([3.1400]), tensor([2.5470]), tensor([2.5200]), tensor([1.4300]), tensor([2.4300]), tensor([-0.9390]), tensor([3.1670]), tensor([3.8200]), tensor([2.7100]), tensor([2.3380]), tensor([2.0780]), tensor([0.1600]), tensor([3.6060]), tensor([0.3030]), tensor([0.7200]), tensor([0.9900]), tensor([3.8820]), tensor([2.5100]), tensor([3.4700]), tensor([5.1800]), tensor([-0.0600]), tensor([3.5200]), tensor([3.8580]), tensor([3.6000]), tensor([4.2900]), tensor([3.2700]), tensor([0.6990]), tensor([4.0900]), tensor([-0.2240]), tensor([-1.3200]), tensor([6.4100]), tensor([3.2830]), tensor([3.2660]), tensor([1.9100]), tensor([3.5400]), tensor([2.9000]), tensor([3.0140]), tensor([2.1600]), tensor([3.3500]), tensor([3.0270]), tensor([2.8100]), tensor([-1.7430]), tensor([2.3300]), tensor([3.2700]), tensor([2.7100]), tensor([2.4100]), tensor([1.0300]), tensor([1.5300]), tensor([4.2120]), tensor([3.1080]), tensor([2.7800]), tensor([2.1700]), tensor([5.0140]), tensor([2.7890]), tensor([2.6500]), tensor([1.1610]), tensor([3.8200]), tensor([4.0900]), tensor([3.1190]), tensor([-1.1220]), tensor([3.6600]), tensor([1.4700]), tensor([4.2800]), tensor([2.5500]), tensor([-0.6800]), tensor([3.2000]), tensor([4.1400]), tensor([3.2400]), tensor([3.5830]), tensor([3.9600]), tensor([3.0340]), tensor([3.3790]), tensor([3.8900]), tensor([2.9600]), tensor([14.1670]), tensor([0.3900]), tensor([1.1300]), tensor([-0.2900]), tensor([9.6000]), tensor([3.2300]), tensor([5.3100]), tensor([3.2100]), tensor([2.8900]), tensor([2.5700]), tensor([-0.1600]), tensor([2.8200]), tensor([2.7700]), tensor([2.5740]), tensor([3.4210]), tensor([3.9220]), tensor([2.8900]), tensor([3.6800]), tensor([2.7630]), tensor([2.2500]), tensor([3.1050]), tensor([3.8700]), tensor([2.4300]), tensor([3.3600]), tensor([2.9230]), tensor([3.1700]), tensor([2.2900]), tensor([1.5040]), tensor([3.2090]), tensor([-0.0540]), tensor([5.0200]), tensor([3.6000]), tensor([3.5040]), tensor([-1.5700]), tensor([1.2760]), tensor([3.5760]), tensor([1.3100]), tensor([3.]), tensor([2.0500]), tensor([3.1100]), tensor([3.9180]), tensor([1.8300]), tensor([2.3800]), tensor([3.0340]), tensor([3.2230]), tensor([6.]), tensor([1.5500]), tensor([2.5500]), tensor([4.4600]), tensor([0.0960]), tensor([1.9500]), tensor([-1.0600]), tensor([2.4100]), tensor([0.0400]), tensor([4.5500]), tensor([4.5800]), tensor([2.8200]), tensor([2.0300]), tensor([2.2350]), tensor([4.9700]), tensor([3.4400]), tensor([3.3400]), tensor([0.3299]), tensor([3.]), tensor([-0.7800]), tensor([4.1630]), tensor([3.2300]), tensor([2.3170]), tensor([2.9260]), tensor([3.5140]), tensor([2.1410]), tensor([2.7980]), tensor([2.7500]), tensor([2.6560]), tensor([3.3300]), tensor([2.5200]), tensor([3.8370]), tensor([1.9800]), tensor([-0.3790]), tensor([1.5350]), tensor([5.6280]), tensor([3.8700]), tensor([4.7550]), tensor([1.3200]), tensor([2.6180]), tensor([4.3300]), tensor([2.8100]), tensor([2.7420]), tensor([2.7700]), tensor([2.9530]), tensor([4.3700]), tensor([2.4300]), tensor([6.6100]), tensor([0.4000]), tensor([-1.3000]), tensor([5.2200]), tensor([0.7500]), tensor([2.4930]), tensor([1.8000]), tensor([1.7860]), tensor([2.7300]), tensor([2.1300]), tensor([2.8400]), tensor([5.1500]), tensor([-0.4450]), tensor([2.7830]), tensor([1.4400]), tensor([-1.4600]), tensor([3.3700]), tensor([1.7000]), tensor([3.0500]), tensor([3.3600]), tensor([2.0700]), tensor([3.2900]), tensor([3.4100]), tensor([1.1900]), tensor([3.9400]), tensor([3.3100]), tensor([2.0990]), tensor([4.6900]), tensor([2.6210]), tensor([1.7500]), tensor([2.3030]), tensor([1.9650]), tensor([2.0300]), tensor([3.1700]), tensor([5.1300]), tensor([3.0700]), tensor([4.3500]), tensor([1.3010]), tensor([3.1300]), tensor([3.5790]), tensor([1.5900]), tensor([-0.7400]), tensor([2.6700]), tensor([-0.4100]), tensor([3.3379]), tensor([2.0100]), tensor([3.0300]), tensor([-0.5800]), tensor([1.8400]), tensor([3.2300]), tensor([4.]), tensor([5.3400]), tensor([2.5200]), tensor([3.0690]), tensor([2.5400]), tensor([2.8620]), tensor([-0.6500]), tensor([4.3100]), tensor([-1.3600]), tensor([3.2460]), tensor([3.4500]), tensor([3.4300]), tensor([5.2900]), tensor([-0.8100]), tensor([2.4700]), tensor([4.0500]), tensor([2.4300]), tensor([3.5600]), tensor([-2.0800]), tensor([3.9185]), tensor([1.9200]), tensor([1.4600]), tensor([3.7130]), tensor([2.7100]), tensor([2.9970]), tensor([1.]), tensor([2.9600]), tensor([3.5860]), tensor([-0.2900]), tensor([1.5090]), tensor([2.9100]), tensor([3.6870]), tensor([-0.1600]), tensor([0.5900]), tensor([1.7900]), tensor([3.1810]), tensor([-1.0170]), tensor([4.7000]), tensor([3.3200]), tensor([3.7500]), tensor([3.1600]), tensor([3.1100]), tensor([3.1350]), tensor([3.0830]), tensor([1.6500]), tensor([5.2000]), tensor([3.5100]), tensor([5.3900]), tensor([2.8900]), tensor([2.3570]), tensor([3.1690]), tensor([3.8480]), tensor([2.2300]), tensor([-0.4830]), tensor([2.6500]), tensor([2.5600]), tensor([3.3300]), tensor([2.3400]), tensor([1.8000]), tensor([3.2850]), tensor([2.0600]), tensor([2.7800]), tensor([2.3330]), tensor([2.3120]), tensor([4.9800]), tensor([2.2200]), tensor([3.5670]), tensor([2.9000]), tensor([-0.4110]), tensor([3.5900]), tensor([3.1830]), tensor([1.6720]), tensor([1.8700]), tensor([3.8800]), tensor([3.4800]), tensor([-1.6500]), tensor([2.8740]), tensor([0.8200]), tensor([-0.7100]), tensor([5.1800]), tensor([2.2200]), tensor([0.8500]), tensor([1.3140]), tensor([3.3700]), tensor([7.5600]), tensor([3.7000]), tensor([3.6600]), tensor([3.8200]), tensor([2.5100]), tensor([3.9930]), tensor([3.4500]), tensor([2.9500]), tensor([2.0900]), tensor([4.0100]), tensor([1.9400]), tensor([3.6710]), tensor([1.8080]), tensor([1.9260]), tensor([2.3050]), tensor([4.5000]), tensor([0.9800]), tensor([4.2000]), tensor([3.9800]), tensor([3.5600]), tensor([-0.7900]), tensor([-1.0360]), tensor([4.7540]), tensor([3.1560]), tensor([2.7850]), tensor([1.8260]), tensor([1.8500]), tensor([2.5900]), tensor([3.2700]), tensor([3.1800]), tensor([0.6810]), tensor([4.2230]), tensor([2.9933]), tensor([-0.8880]), tensor([2.4290]), tensor([5.0700]), tensor([2.9520]), tensor([6.0380]), tensor([3.5720]), tensor([3.8110]), tensor([4.8700]), tensor([-0.4740]), tensor([3.6130]), tensor([3.6300]), tensor([5.9100]), tensor([3.2970]), tensor([3.3350]), tensor([-0.4560]), tensor([3.5510]), tensor([2.0500]), tensor([1.7990]), tensor([4.4130]), tensor([5.7500]), tensor([3.1400]), tensor([2.8800]), tensor([1.2020]), tensor([3.2400]), tensor([1.7040]), tensor([2.5900]), tensor([3.3900]), tensor([4.6400]), tensor([0.8500]), tensor([2.7000]), tensor([-0.6090]), tensor([2.8900]), tensor([3.6600]), tensor([3.3300]), tensor([4.3500]), tensor([2.3400]), tensor([1.0600]), tensor([3.2500]), tensor([1.1700]), tensor([0.3100]), tensor([4.3100]), tensor([2.1400]), tensor([2.0300]), tensor([1.2400]), tensor([3.1000]), tensor([-0.9900]), tensor([3.0700]), tensor([2.2500]), tensor([4.4300]), tensor([1.8710]), tensor([2.5210]), tensor([9.9000]), tensor([1.6560]), tensor([3.3360]), tensor([3.2700]), tensor([1.7300]), tensor([3.6400]), tensor([2.8300]), tensor([2.8300]), tensor([3.1400]), tensor([-0.2190]), tensor([2.5000]), tensor([3.6400]), tensor([2.8060]), tensor([2.1300]), tensor([2.0400]), tensor([1.1400]), tensor([4.2330]), tensor([5.6400]), tensor([3.7000]), tensor([2.9100]), tensor([3.6300]), tensor([2.9600]), tensor([1.0900]), tensor([3.7100]), tensor([0.3560]), tensor([3.7470]), tensor([-1.4100]), tensor([-1.7060]), tensor([0.0900]), tensor([2.6700]), tensor([1.7100]), tensor([3.5300]), tensor([1.9700]), tensor([2.6400]), tensor([2.9800]), tensor([3.4400]), tensor([-1.4530]), tensor([5.1300]), tensor([2.8895]), tensor([1.3000]), tensor([3.6900]), tensor([4.7700]), tensor([3.3900]), tensor([0.3640]), tensor([1.4700]), tensor([-0.4280]), tensor([1.7500]), tensor([4.2250]), tensor([3.9820]), tensor([1.2900]), tensor([6.2900]), tensor([2.5900]), tensor([3.2300]), tensor([1.5000]), tensor([3.3880]), tensor([3.1800]), tensor([0.3600]), tensor([0.3900]), tensor([-0.7490]), tensor([3.9380]), tensor([4.2580]), tensor([3.7850]), tensor([3.6640]), tensor([2.4720]), tensor([2.3300]), tensor([2.9400]), tensor([3.0300]), tensor([6.3500]), tensor([3.0230]), tensor([6.9600]), tensor([2.7800]), tensor([1.2480]), tensor([3.1540]), tensor([3.1470]), tensor([2.6388]), tensor([-0.5950]), tensor([0.4500]), tensor([-1.0690]), tensor([2.4300]), tensor([5.3100]), tensor([3.0500]), tensor([-0.6880]), tensor([2.6200]), tensor([3.7810]), tensor([2.5800]), tensor([4.6860]), tensor([2.8770]), tensor([3.3070]), tensor([3.1200]), tensor([2.3400]), tensor([1.5200]), tensor([3.1700]), tensor([-0.0900]), tensor([-0.7400]), tensor([3.5580]), tensor([-0.4710]), tensor([1.9020]), tensor([-0.8900]), tensor([4.3200]), tensor([4.6700]), tensor([-1.3100]), tensor([4.3590]), tensor([2.1300]), tensor([3.0900]), tensor([3.3858]), tensor([7.1300]), tensor([2.9100]), tensor([1.6880]), tensor([3.7800]), tensor([2.3600]), tensor([3.4200]), tensor([2.4400]), tensor([4.3340]), tensor([3.7500]), tensor([3.5200]), tensor([2.6400]), tensor([2.5700]), tensor([2.9300]), tensor([1.9860]), tensor([3.1270]), tensor([4.4750]), tensor([-0.8010]), tensor([1.9600]), tensor([1.6000]), tensor([3.3400]), tensor([2.4200]), tensor([1.9960]), tensor([-1.4600]), tensor([3.7300]), tensor([2.2500]), tensor([1.6200]), tensor([-0.8400]), tensor([3.2700]), tensor([1.8100]), tensor([2.8500]), tensor([2.6850]), tensor([1.5090]), tensor([2.9430]), tensor([1.7720]), tensor([3.8530]), tensor([-1.4500]), tensor([3.1200]), tensor([3.4960]), tensor([-1.1100]), tensor([3.9090]), tensor([2.]), tensor([2.2010]), tensor([-0.6850]), tensor([1.8410]), tensor([2.6240]), tensor([3.9700]), tensor([4.5200]), tensor([5.2920]), tensor([0.4800]), tensor([3.1200]), tensor([3.3790]), tensor([2.8710]), tensor([4.0500]), tensor([2.7000]), tensor([4.0700]), tensor([3.4200]), tensor([3.6400]), tensor([3.3790]), tensor([3.6800]), tensor([2.9700]), tensor([1.1300]), tensor([2.8400]), tensor([6.5000]), tensor([4.2290]), tensor([3.5900]), tensor([3.6700]), tensor([4.9700]), tensor([1.7300]), tensor([3.4390]), tensor([0.5800]), tensor([0.7400]), tensor([1.9300]), tensor([-1.2900]), tensor([-0.6900]), tensor([4.7900]), tensor([2.1900]), tensor([2.1200]), tensor([2.5200]), tensor([-0.8700]), tensor([2.6190]), tensor([2.6790]), tensor([5.0100]), tensor([2.8780]), tensor([3.3200]), tensor([2.8120]), tensor([3.8300]), tensor([3.3100]), tensor([1.7700]), tensor([2.3224]), tensor([1.4500]), tensor([2.3500]), tensor([1.9400]), tensor([3.2900]), tensor([3.4500]), tensor([2.2500]), tensor([3.4190]), tensor([2.7400]), tensor([1.9400]), tensor([-0.1600]), tensor([3.8560]), tensor([1.6300]), tensor([1.0140]), tensor([2.5000]), tensor([0.7570]), tensor([4.6500]), tensor([4.9700]), tensor([2.2300]), tensor([4.1200]), tensor([-0.0500]), tensor([-0.6080]), tensor([0.4210]), tensor([3.9800]), tensor([4.1900]), tensor([-0.7670]), tensor([0.0800]), tensor([4.9100]), tensor([3.0500]), tensor([3.6650]), tensor([2.4130]), tensor([3.3700]), tensor([1.8100]), tensor([1.7700]), tensor([1.4900]), tensor([3.2800]), tensor([3.]), tensor([-1.0540]), tensor([3.5300]), tensor([1.8700]), tensor([2.7300]), tensor([3.0490]), tensor([2.9390]), tensor([3.9700]), tensor([2.2200]), tensor([-0.7200]), tensor([3.1000]), tensor([-0.9900]), tensor([1.4300]), tensor([3.3900]), tensor([-0.9550]), tensor([2.2900]), tensor([3.8800]), tensor([2.5770]), tensor([3.2100]), tensor([1.2500]), tensor([2.9740]), tensor([1.5900]), tensor([4.7600]), tensor([-1.0220]), tensor([3.3100]), tensor([2.8170]), tensor([2.6800]), tensor([2.0100]), tensor([3.5200]), tensor([3.6800]), tensor([2.5000]), tensor([2.8600]), tensor([2.6300]), tensor([2.4100]), tensor([3.3400]), tensor([3.2800]), tensor([2.8960]), tensor([3.4500]), tensor([7.7920]), tensor([0.1090]), tensor([2.8400]), tensor([3.5800]), tensor([3.1900]), tensor([3.1000]), tensor([0.1911]), tensor([0.3200]), tensor([3.8320]), tensor([1.6900]), tensor([-1.1030]), tensor([1.6300]), tensor([3.7730]), tensor([-1.7410]), tensor([2.4700]), tensor([2.2700]), tensor([3.8300]), tensor([4.4900]), tensor([2.9700]), tensor([-0.8000]), tensor([4.7400]), tensor([3.0700]), tensor([3.5350]), tensor([-0.5600]), tensor([4.1300]), tensor([1.8150]), tensor([3.6980]), tensor([4.8000]), tensor([3.1300]), tensor([4.4700]), tensor([2.5260]), tensor([3.4500]), tensor([2.0600]), tensor([-0.0600]), tensor([5.0900]), tensor([3.1400]), tensor([1.7770]), tensor([4.2810]), tensor([3.2310]), tensor([2.8880]), tensor([5.1800]), tensor([2.9100]), tensor([2.3300]), tensor([2.1100]), tensor([3.2000]), tensor([3.4290]), tensor([-0.2500]), tensor([3.7400]), tensor([4.4500]), tensor([3.2600]), tensor([2.6400]), tensor([2.6350]), tensor([3.5000]), tensor([-1.7250]), tensor([3.4600]), tensor([3.7140]), tensor([1.9700]), tensor([3.3700]), tensor([2.2780]), tensor([3.6060]), tensor([3.0600]), tensor([4.3060]), tensor([2.5910]), tensor([2.4100]), tensor([5.0200]), tensor([2.6300]), tensor([4.6610]), tensor([3.6210]), tensor([0.4000]), tensor([2.3600]), tensor([2.3340]), tensor([3.3240]), tensor([3.1900]), tensor([2.6900]), tensor([3.1040]), tensor([3.9900]), tensor([3.1200]), tensor([2.1200]), tensor([0.9800]), tensor([3.4740]), tensor([3.1700]), tensor([1.8800]), tensor([3.1387]), tensor([4.3680]), tensor([3.8460]), tensor([0.5300]), tensor([2.8800]), tensor([2.8300]), tensor([4.1400]), tensor([2.7800]), tensor([0.6400]), tensor([1.8100]), tensor([2.8800]), tensor([3.3800]), tensor([3.1720]), tensor([3.8800]), tensor([2.]), tensor([-1.0400]), tensor([2.1100]), tensor([2.1900]), tensor([1.9100]), tensor([4.6220]), tensor([-0.1900]), tensor([3.4300]), tensor([3.5310]), tensor([3.7900]), tensor([4.7000]), tensor([2.7700]), tensor([4.2920]), tensor([-0.6680]), tensor([1.7880]), tensor([3.7700]), tensor([2.7500]), tensor([2.9200]), tensor([4.9400]), tensor([1.8700]), tensor([3.7600]), tensor([3.2920]), tensor([3.8400]), tensor([1.1850]), tensor([1.4000]), tensor([3.6500]), tensor([2.3600]), tensor([-1.]), tensor([1.9200]), tensor([2.9250]), tensor([5.4100]), tensor([0.6300]), tensor([3.7800]), tensor([1.8300]), tensor([3.4300]), tensor([2.3000]), tensor([-0.1110]), tensor([4.3406]), tensor([3.1160]), tensor([4.6100]), tensor([1.8500]), tensor([3.5980]), tensor([2.0200]), tensor([3.3400]), tensor([3.6700]), tensor([1.7470]), tensor([1.8060]), tensor([4.6900]), tensor([0.5790]), tensor([2.1190]), tensor([2.7300]), tensor([1.1700]), tensor([2.7000]), tensor([2.7600]), tensor([2.7020]), tensor([7.5400]), tensor([1.7880]), tensor([2.9050]), tensor([2.1880]), tensor([2.5800]), tensor([3.7900]), tensor([3.9200]), tensor([2.8100]), tensor([3.0300]), tensor([3.6200]), tensor([2.8500]), tensor([3.4400]), tensor([7.8300]), tensor([3.6800]), tensor([1.5300]), tensor([2.5800]), tensor([0.5110]), tensor([3.5100]), tensor([3.7500]), tensor([2.6200]), tensor([1.6230]), tensor([3.6150]), tensor([2.7630]), tensor([3.9800]), tensor([1.5370]), tensor([2.3900]), tensor([3.7550]), tensor([2.6300]), tensor([1.2900]), tensor([4.5200]), tensor([3.2960]), tensor([4.9370]), tensor([3.1700]), tensor([3.2500]), tensor([2.0800]), tensor([3.3070]), tensor([1.1160]), tensor([-0.8800]), tensor([-0.6610]), tensor([4.7140]), tensor([2.2700]), tensor([-0.2400]), tensor([3.0200]), tensor([-0.7960]), tensor([3.0400]), tensor([5.2100]), tensor([2.4900]), tensor([4.3300]), tensor([3.6200]), tensor([1.5730]), tensor([3.2900]), tensor([0.5000]), tensor([0.4460]), tensor([1.3200]), tensor([2.7340]), tensor([3.1840]), tensor([1.9400]), tensor([-1.5600]), tensor([3.1940]), tensor([4.]), tensor([-0.4000]), tensor([0.4700]), tensor([2.0300]), tensor([0.6500]), tensor([1.1500]), tensor([3.8350]), tensor([2.9500]), tensor([3.0100]), tensor([3.1220]), tensor([3.2000]), tensor([7.4000]), tensor([3.4160]), tensor([2.7890]), tensor([2.4240]), tensor([3.6280]), tensor([3.1050]), tensor([5.1300]), tensor([1.5010]), tensor([1.2200]), tensor([4.4500]), tensor([2.5900]), tensor([2.7300]), tensor([2.6300]), tensor([-0.4570]), tensor([-0.6000]), tensor([3.3000]), tensor([2.6600]), tensor([2.6900]), tensor([2.8300]), tensor([4.2700]), tensor([3.0600]), tensor([4.2660]), tensor([3.9700]), tensor([-1.8040]), tensor([5.3500]), tensor([3.6700]), tensor([5.6700]), tensor([-0.6820]), tensor([4.1010]), tensor([5.0400]), tensor([4.1850]), tensor([3.0700]), tensor([3.0630]), tensor([2.1900]), tensor([2.7500]), tensor([-0.6410]), tensor([3.3500]), tensor([1.5300]), tensor([1.6900]), tensor([4.4000]), tensor([1.8800]), tensor([8.2000]), tensor([2.6700]), tensor([2.9200]), tensor([-0.0250]), tensor([3.1800]), tensor([3.5240]), tensor([3.9700]), tensor([2.4710]), tensor([4.1590]), tensor([3.1420]), tensor([0.1300]), tensor([3.3560]), tensor([0.8200]), tensor([4.5800]), tensor([-0.7090]), tensor([3.0100]), tensor([2.4400]), tensor([0.6800]), tensor([-0.5300]), tensor([2.9800]), tensor([6.2900]), tensor([-0.5600]), tensor([2.6300]), tensor([3.5300]), tensor([5.2100]), tensor([0.6300]), tensor([4.2800]), tensor([3.7350]), tensor([2.6600]), tensor([2.7260]), tensor([3.0700]), tensor([1.9400]), tensor([2.4800]), tensor([1.6300]), tensor([0.9460]), tensor([3.3720]), tensor([3.3540]), tensor([1.8500]), tensor([3.0200]), tensor([-0.2300]), tensor([3.8610]), tensor([3.3300]), tensor([6.5700]), tensor([1.3900]), tensor([3.5100]), tensor([2.8100]), tensor([1.7900]), tensor([3.2250]), tensor([3.1600]), tensor([2.6700]), tensor([6.3210]), tensor([1.4620]), tensor([-0.5700]), tensor([2.9700]), tensor([2.8300]), tensor([3.2680]), tensor([-0.9400]), tensor([0.9600]), tensor([6.8400]), tensor([6.2300]), tensor([1.6600]), tensor([3.9990]), tensor([3.5300]), tensor([4.2730]), tensor([3.6810]), tensor([2.1400]), tensor([0.1490]), tensor([2.1740]), tensor([3.1379]), tensor([2.3100]), tensor([3.6000]), tensor([-0.1400]), tensor([3.4400]), tensor([3.4200]), tensor([1.3700]), tensor([3.8400]), tensor([1.9600]), tensor([3.4100]), tensor([3.7300]), tensor([2.3400]), tensor([2.3070]), tensor([3.7630]), tensor([3.0400]), tensor([3.3060]), tensor([3.0100]), tensor([2.1700]), tensor([4.1740]), tensor([1.3100]), tensor([5.8400]), tensor([1.7600]), tensor([4.8260]), tensor([2.3500]), tensor([5.2000]), tensor([3.6660]), tensor([2.5500]), tensor([2.9340]), tensor([-0.7890]), tensor([0.8160]), tensor([3.6400]), tensor([5.3100]), tensor([2.9500]), tensor([2.7000]), tensor([3.4800]), tensor([3.2500]), tensor([2.6720]), tensor([4.3900]), tensor([2.6600]), tensor([2.5240]), tensor([3.7100]), tensor([3.6360]), tensor([3.4800]), tensor([2.6800]), tensor([2.8400]), tensor([4.0210]), tensor([3.2410]), tensor([0.1000]), tensor([3.1960]), tensor([0.6900]), tensor([3.0500]), tensor([2.0100]), tensor([3.8600]), tensor([4.0300]), tensor([3.4200]), tensor([5.]), tensor([4.0700]), tensor([5.5400]), tensor([0.3870]), tensor([3.2900]), tensor([-0.6000]), tensor([-0.9100]), tensor([-0.0750]), tensor([-0.0700]), tensor([3.1300]), tensor([1.9410]), tensor([1.3060]), tensor([3.6600]), tensor([7.5300]), tensor([2.8500]), tensor([3.1270]), tensor([6.6100]), tensor([2.8500]), tensor([3.3700]), tensor([2.5900]), tensor([3.4300]), tensor([4.3800]), tensor([1.6200]), tensor([2.4700]), tensor([3.4650]), tensor([2.0450]), tensor([3.5300]), tensor([4.4400]), tensor([3.2000]), tensor([1.4300]), tensor([2.5900]), tensor([-0.8200]), tensor([3.2300]), tensor([2.7030]), tensor([2.4100]), tensor([3.8600]), tensor([4.0040]), tensor([3.6110]), tensor([4.6340]), tensor([2.8700]), tensor([2.9500]), tensor([3.5500]), tensor([1.8120]), tensor([2.8600]), tensor([3.1600]), tensor([-0.1300]), tensor([3.1100]), tensor([3.0500]), tensor([-0.6000]), tensor([2.5820]), tensor([4.1500]), tensor([2.8490]), tensor([-0.9500]), tensor([3.8200]), tensor([5.7400]), tensor([3.3910]), tensor([3.1300]), tensor([-0.5880]), tensor([1.8500]), tensor([2.3400]), tensor([2.4900]), tensor([3.7240]), tensor([5.0700]), tensor([-1.1400]), tensor([2.9620]), tensor([4.0200]), tensor([2.4870]), tensor([4.1050]), tensor([2.6200]), tensor([2.6715]), tensor([2.7100]), tensor([2.9700]), tensor([3.0200]), tensor([1.8600]), tensor([4.2100]), tensor([-0.5900]), tensor([5.8640]), tensor([3.2100]), tensor([-1.5200]), tensor([2.7100]), tensor([5.7900]), tensor([2.9900]), tensor([3.1000]), tensor([5.0800]), tensor([2.1900]), tensor([1.7900]), tensor([0.5100]), tensor([3.0400]), tensor([2.7610]), tensor([3.3670]), tensor([4.5580]), tensor([2.4930]), tensor([2.7700]), tensor([3.6600]), tensor([4.5600]), tensor([2.2100]), tensor([1.7700]), tensor([4.5460]), tensor([1.2600]), tensor([3.4400]), tensor([4.3470]), tensor([0.0100]), tensor([2.9600]), tensor([3.6100]), tensor([4.2420]), tensor([3.0900]), tensor([0.4010]), tensor([2.7230]), tensor([3.8500]), tensor([2.6040]), tensor([3.4590]), tensor([2.2500]), tensor([3.8100]), tensor([3.2800]), tensor([3.6400]), tensor([2.4920]), tensor([2.5660]), tensor([4.9600]), tensor([2.7810]), tensor([3.6700]), tensor([3.0370]), tensor([3.2200]), tensor([3.0060]), tensor([2.9500]), tensor([3.4400]), tensor([-0.3300]), tensor([3.2900]), tensor([5.4400]), tensor([2.7800]), tensor([5.3100]), tensor([1.]), tensor([3.4400]), tensor([0.2400]), tensor([-0.0600]), tensor([3.3400]), tensor([2.5190]), tensor([0.3360]), tensor([3.9500]), tensor([5.4000]), tensor([4.3470]), tensor([3.7968]), tensor([5.9300]), tensor([2.4100]), tensor([2.8800]), tensor([-0.5300]), tensor([4.2130]), tensor([2.9900]), tensor([1.6300]), tensor([3.2500]), tensor([3.2700]), tensor([2.8100]), tensor([2.6200]), tensor([4.4100]), tensor([0.4300]), tensor([1.5720]), tensor([3.8260]), tensor([3.7110]), tensor([3.6400]), tensor([1.4900]), tensor([3.3000]), tensor([2.2700]), tensor([3.0500]), tensor([2.7800]), tensor([2.5400]), tensor([3.3900]), tensor([2.5900]), tensor([3.5400]), tensor([1.9020]), tensor([2.1600]), tensor([3.0190]), tensor([3.3200]), tensor([1.7800]), tensor([4.0310]), tensor([1.6800]), tensor([3.4290]), tensor([2.6600]), tensor([-0.6280]), tensor([4.7100]), tensor([3.5800]), tensor([1.4500]), tensor([4.9200]), tensor([3.2200]), tensor([3.8570]), tensor([3.6680]), tensor([1.6610]), tensor([2.9700]), tensor([4.5200]), tensor([7.2400]), tensor([3.5700]), tensor([2.1300]), tensor([4.4530]), tensor([1.5100]), tensor([3.9120]), tensor([2.7300]), tensor([3.3350]), tensor([-1.7200]), tensor([1.4900]), tensor([2.8600]), tensor([2.9800]), tensor([-0.8000]), tensor([2.8030]), tensor([2.2700]), tensor([1.8800]), tensor([0.9900]), tensor([3.5400]), tensor([2.0870]), tensor([-0.6370]), tensor([2.9100]), tensor([6.0100]), tensor([2.2900]), tensor([-0.9090]), tensor([7.1400]), tensor([3.3400]), tensor([3.9400]), tensor([4.8870]), tensor([2.9200]), tensor([2.9550]), tensor([2.2900]), tensor([3.0420]), tensor([0.9900]), tensor([1.3900]), tensor([3.4700]), tensor([1.7900]), tensor([2.9200]), tensor([2.2560]), tensor([2.9000]), tensor([2.2800]), tensor([-1.0910]), tensor([2.1700]), tensor([3.6230]), tensor([2.1800]), tensor([-0.5800]), tensor([2.7000]), tensor([3.0400]), tensor([3.9886]), tensor([3.5550]), tensor([3.5200]), tensor([1.2550]), tensor([-1.3430]), tensor([2.1300]), tensor([1.7400]), tensor([2.3100]), tensor([4.1600]), tensor([4.6000]), tensor([2.6420]), tensor([4.3400]), tensor([-1.4850]), tensor([0.9500]), tensor([2.6270]), tensor([4.6500]), tensor([1.8200]), tensor([3.2140]), tensor([2.9150]), tensor([3.1650]), tensor([4.2000]), tensor([2.9600]), tensor([3.0600]), tensor([3.1300]), tensor([3.9100]), tensor([-0.2000]), tensor([3.6000]), tensor([3.2000]), tensor([3.2600]), tensor([2.]), tensor([6.9800]), tensor([4.3800]), tensor([12.0600]), tensor([0.5000]), tensor([3.4400]), tensor([0.3320]), tensor([3.0800]), tensor([3.2400]), tensor([3.6480]), tensor([1.4880]), tensor([1.7800]), tensor([4.1700]), tensor([-1.9100]), tensor([2.4900]), tensor([3.2200]), tensor([4.6700]), tensor([2.7900]), tensor([3.2400]), tensor([2.9480]), tensor([2.5600]), tensor([2.8000]), tensor([3.2300]), tensor([3.6600]), tensor([2.5900]), tensor([3.2200]), tensor([4.4700]), tensor([1.7200]), tensor([2.8100]), tensor([2.7490]), tensor([1.2200]), tensor([1.9800]), tensor([2.8800]), tensor([0.5400]), tensor([3.2040]), tensor([0.7200]), tensor([2.5960]), tensor([1.1000]), tensor([2.5600]), tensor([1.2820]), tensor([3.4740]), tensor([2.1900]), tensor([3.9070]), tensor([1.8200]), tensor([2.3800]), tensor([2.9800]), tensor([1.7000]), tensor([4.6400]), tensor([4.1000]), tensor([3.5840]), tensor([2.1000]), tensor([2.8120]), tensor([2.5200]), tensor([2.8700]), tensor([-0.4700]), tensor([2.5200]), tensor([2.8500]), tensor([2.5500]), tensor([2.3100]), tensor([4.6980]), tensor([2.0130]), tensor([3.7300]), tensor([8.3000]), tensor([0.2200]), tensor([1.9120]), tensor([-0.5890]), tensor([0.4500]), tensor([1.1500]), tensor([3.3800]), tensor([4.4700]), tensor([1.8300]), tensor([7.1900]), tensor([2.1500]), tensor([2.7600]), tensor([2.4200]), tensor([1.8210]), tensor([2.6100]), tensor([3.1760]), tensor([2.7200]), tensor([-0.6330]), tensor([1.4000]), tensor([1.6150]), tensor([2.0500]), tensor([2.3900]), tensor([2.6210]), tensor([-1.6040]), tensor([-1.0200]), tensor([4.0100]), tensor([0.4800]), tensor([1.6400]), tensor([1.9550]), tensor([1.4200]), tensor([2.8600]), tensor([2.1200]), tensor([3.8570]), tensor([-1.3900]), tensor([3.1700]), tensor([4.9700]), tensor([2.4470]), tensor([2.6300]), tensor([1.3900]), tensor([2.9200]), tensor([2.8530]), tensor([2.8000]), tensor([2.5040]), tensor([3.7700]), tensor([2.1200]), tensor([1.4900]), tensor([2.3600]), tensor([3.0380]), tensor([3.0770]), tensor([3.6100]), tensor([-0.0400]), tensor([4.1600]), tensor([3.5000]), tensor([3.4670]), tensor([2.9000]), tensor([1.8080]), tensor([2.6300]), tensor([3.2200]), tensor([3.3720]), tensor([2.5700]), tensor([5.3700]), tensor([3.9000]), tensor([5.2600]), tensor([1.9700]), tensor([4.9600]), tensor([-0.8300]), tensor([2.9400]), tensor([2.0800]), tensor([2.3700]), tensor([2.3560]), tensor([1.5400]), tensor([7.5080]), tensor([1.9570]), tensor([6.2800]), tensor([3.1700]), tensor([2.6710]), tensor([-1.7480]), tensor([3.0900]), tensor([5.5800]), tensor([0.5300]), tensor([2.5810]), tensor([1.9840]), tensor([-1.4920]), tensor([3.8010]), tensor([3.4500]), tensor([1.6560]), tensor([4.6810]), tensor([2.3300]), tensor([3.2330]), tensor([3.6182]), tensor([3.3500]), tensor([3.3910]), tensor([3.8750]), tensor([2.7360]), tensor([2.2480]), tensor([3.0400]), tensor([1.0300]), tensor([2.4000]), tensor([2.1110]), tensor([2.6500]), tensor([2.9200]), tensor([0.8500]), tensor([3.4520]), tensor([3.1220]), tensor([2.1080]), tensor([0.3800]), tensor([-1.6300]), tensor([3.2900]), tensor([-0.7600]), tensor([3.0210]), tensor([2.5600]), tensor([2.3620]), tensor([0.1800]), tensor([1.8700]), tensor([2.8400]), tensor([1.6200]), tensor([-0.8600]), tensor([-0.6600]), tensor([2.5980]), tensor([0.7890]), tensor([2.2300]), tensor([4.6000]), tensor([3.7300]), tensor([3.6670]), tensor([1.8050]), tensor([3.9090]), tensor([2.9000]), tensor([1.5900]), tensor([4.8400]), tensor([3.5800]), tensor([2.2770]), tensor([2.7900]), tensor([3.5480]), tensor([-0.0200]), tensor([4.1000]), tensor([4.2700]), tensor([1.3600]), tensor([1.6600]), tensor([1.6100]), tensor([2.1090]), tensor([1.4500]), tensor([2.1230]), tensor([4.0200]), tensor([3.2800]), tensor([2.9830]), tensor([1.4500]), tensor([4.6100]), tensor([3.2620]), tensor([2.6330]), tensor([3.2470]), tensor([1.2270]), tensor([3.5200]), tensor([2.3500]), tensor([3.9000]), tensor([-0.1800]), tensor([0.1500]), tensor([2.1070]), tensor([1.6920]), tensor([0.6800]), tensor([-0.1200]), tensor([1.8500]), tensor([2.4300]), tensor([3.6800]), tensor([2.6990]), tensor([4.5400]), tensor([3.4310]), tensor([0.2500]), tensor([5.4400]), tensor([3.0300]), tensor([1.3800]), tensor([3.1000]), tensor([2.5890]), tensor([0.9300]), tensor([0.4760]), tensor([4.5000]), tensor([2.4800]), tensor([2.6260]), tensor([3.1690]), tensor([-0.9810]), tensor([3.5800]), tensor([3.7200]), tensor([2.8100]), tensor([3.2800]), tensor([4.0500]), tensor([3.2800]), tensor([3.3830]), tensor([1.0400]), tensor([2.1000]), tensor([2.6900]), tensor([3.8600]), tensor([6.5700]), tensor([3.8910]), tensor([5.1000]), tensor([3.1734]), tensor([1.6370]), tensor([2.3300]), tensor([3.8200]), tensor([3.1939]), tensor([-1.0800]), tensor([3.9000]), tensor([3.0239]), tensor([-0.8270]), tensor([2.6800]), tensor([4.9300]), tensor([2.6500]), tensor([1.9600]), tensor([4.1600]), tensor([3.7400]), tensor([4.6900]), tensor([2.9870]), tensor([2.4420]), tensor([-0.3600]), tensor([2.9300]), tensor([5.]), tensor([1.9800]), tensor([2.7400]), tensor([3.1700]), tensor([3.3700]), tensor([1.7440]), tensor([2.7640]), tensor([3.5800]), tensor([3.4500]), tensor([-1.2200]), tensor([4.3990]), tensor([-0.7000]), tensor([3.6200]), tensor([7.2200]), tensor([3.2500]), tensor([1.6530]), tensor([1.4600]), tensor([3.4400]), tensor([-1.1450]), tensor([3.9120]), tensor([3.1900]), tensor([2.3430]), tensor([0.2800]), tensor([3.3780]), tensor([3.0500]), tensor([0.3900]), tensor([3.1800]), tensor([6.0200]), tensor([2.4500]), tensor([2.1400]), tensor([0.9700]), tensor([-1.4000]), tensor([6.5200]), tensor([2.8100]), tensor([-0.5300]), tensor([2.9700]), tensor([3.5100]), tensor([4.3800]), tensor([1.4800]), tensor([3.6100]), tensor([-0.2200]), tensor([3.9400]), tensor([0.3900]), tensor([4.2800]), tensor([-0.9900]), tensor([3.5700]), tensor([0.7100]), tensor([3.0030]), tensor([-0.8280]), tensor([3.3720]), tensor([3.0520]), tensor([2.8300]), tensor([-0.3800]), tensor([2.9200]), tensor([-0.9940]), tensor([2.3000]), tensor([4.5300]), tensor([5.4000]), tensor([2.7100]), tensor([5.1800]), tensor([-1.0700]), tensor([3.4200]), tensor([1.3100]), tensor([7.0600]), tensor([0.7300]), tensor([3.7560]), tensor([3.6900]), tensor([2.3800]), tensor([2.9640]), tensor([2.4760]), tensor([4.0500]), tensor([3.3780]), tensor([3.3400]), tensor([1.5600]), tensor([4.0920]), tensor([1.4100]), tensor([3.1600]), tensor([3.2100]), tensor([0.7970]), tensor([1.5900]), tensor([3.2700]), tensor([2.9100]), tensor([2.2000]), tensor([2.8150]), tensor([3.1900]), tensor([2.4500]), tensor([3.9900]), tensor([0.8290]), tensor([2.8900]), tensor([2.2700]), tensor([2.0730]), tensor([2.8400]), tensor([2.1300]), tensor([4.8700]), tensor([4.0500]), tensor([4.2200]), tensor([5.2600]), tensor([2.8000]), tensor([3.5040]), tensor([2.8104]), tensor([4.8900]), tensor([4.5900]), tensor([2.5200]), tensor([3.8700]), tensor([2.3880]), tensor([2.7300]), tensor([1.6500]), tensor([2.9261]), tensor([3.2900]), tensor([3.3890]), tensor([6.7900]), tensor([4.1300]), tensor([2.3100]), tensor([2.3920]), tensor([4.1240]), tensor([3.2300]), tensor([2.4200]), tensor([3.2070]), tensor([2.7100]), tensor([-0.2040]), tensor([1.6720]), tensor([1.5500]), tensor([2.8400]), tensor([3.8500]), tensor([4.0840]), tensor([1.9420]), tensor([3.0100]), tensor([3.8600]), tensor([3.6400]), tensor([4.0650]), tensor([3.0700]), tensor([3.7100]), tensor([2.2200]), tensor([2.7600]), tensor([5.1770]), tensor([4.2000]), tensor([3.2300]), tensor([6.7700]), tensor([2.1900]), tensor([3.4100]), tensor([2.1750]), tensor([0.2900]), tensor([1.3000]), tensor([1.8200]), tensor([4.3700]), tensor([2.3680]), tensor([2.4100]), tensor([2.2420]), tensor([1.6830]), tensor([0.9900]), tensor([3.2273]), tensor([2.1700]), tensor([0.6000]), tensor([3.4460]), tensor([-0.5800]), tensor([1.4798]), tensor([2.6240]), tensor([4.5700]), tensor([3.5470]), tensor([3.8600]), tensor([3.9604]), tensor([5.8200]), tensor([-0.8250]), tensor([3.6250]), tensor([2.5620]), tensor([2.9000]), tensor([3.9000]), tensor([3.0960]), tensor([3.4600]), tensor([4.2300]), tensor([4.1700]), tensor([2.6400]), tensor([3.1810]), tensor([0.8900]), tensor([-1.5400]), tensor([3.6400]), tensor([1.8500]), tensor([1.4700]), tensor([2.9600]), tensor([2.9870]), tensor([2.9200]), tensor([2.8400]), tensor([4.6100]), tensor([-0.6620]), tensor([2.4300]), tensor([0.4500]), tensor([0.3280]), tensor([1.5290]), tensor([3.7500]), tensor([2.6900]), tensor([1.9000]), tensor([3.5300]), tensor([3.5700]), tensor([0.1900]), tensor([8.0900]), tensor([1.4620]), tensor([-0.7600]), tensor([-0.8800]), tensor([2.5700]), tensor([4.5300]), tensor([0.1200]), tensor([2.4350]), tensor([5.0600]), tensor([4.6200]), tensor([5.2100]), tensor([3.4800]), tensor([4.0090]), tensor([1.3700]), tensor([5.4100]), tensor([2.3400]), tensor([2.2600]), tensor([2.2490]), tensor([3.4680]), tensor([-0.9320]), tensor([6.0100]), tensor([-1.3700]), tensor([6.]), tensor([4.3200]), tensor([5.5400]), tensor([4.4900]), tensor([2.4010]), tensor([2.9500]), tensor([4.8770]), tensor([3.8600]), tensor([4.0010]), tensor([1.5300]), tensor([-0.8700]), tensor([4.0700]), tensor([3.6840]), tensor([5.5600]), tensor([1.5800]), tensor([1.6300]), tensor([2.2400]), tensor([3.7800]), tensor([2.5200]), tensor([4.2720]), tensor([2.6660]), tensor([1.9210]), tensor([2.5800]), tensor([2.5990]), tensor([2.9610]), tensor([2.7700]), tensor([0.3180]), tensor([1.3900]), tensor([1.2000]), tensor([2.4900]), tensor([3.1700]), tensor([4.7000]), tensor([2.9000]), tensor([1.7100]), tensor([3.0930]), tensor([1.7510]), tensor([4.5200]), tensor([3.4800]), tensor([3.0100]), tensor([2.6243]), tensor([2.0400]), tensor([-1.2350]), tensor([4.1300]), tensor([4.7500]), tensor([1.2700]), tensor([2.9130]), tensor([-1.8000]), tensor([2.7460]), tensor([3.4400]), tensor([3.3400]), tensor([2.4800]), tensor([2.5140]), tensor([1.5900]), tensor([4.5100]), tensor([3.2500]), tensor([4.3700]), tensor([3.2600]), tensor([-0.6100]), tensor([2.3670]), tensor([0.7260]), tensor([-0.9600]), tensor([3.0560]), tensor([4.4180]), tensor([0.3600]), tensor([3.7650]), tensor([-0.8500]), tensor([2.3100]), tensor([2.2160]), tensor([2.4600]), tensor([4.9000]), tensor([2.9900]), tensor([1.3100]), tensor([1.9960]), tensor([2.7100]), tensor([2.9900]), tensor([-0.9700]), tensor([3.4840]), tensor([2.5250]), tensor([8.1000]), tensor([-0.8300]), tensor([1.0500]), tensor([3.5400]), tensor([4.2570]), tensor([3.6200]), tensor([2.2600]), tensor([-0.2300]), tensor([1.5100]), tensor([2.7300]), tensor([-0.4370]), tensor([3.9300]), tensor([3.5800]), tensor([3.2600]), tensor([-0.5360]), tensor([1.5700]), tensor([4.2360]), tensor([0.5500]), tensor([3.8100]), tensor([3.6300]), tensor([3.3740]), tensor([2.5900]), tensor([2.7100]), tensor([3.0590]), tensor([4.8100]), tensor([1.8700]), tensor([2.7662]), tensor([7.1600]), tensor([1.5700]), tensor([3.6400]), tensor([0.3700]), tensor([2.7760]), tensor([3.7970]), tensor([-0.8100]), tensor([2.3030]), tensor([0.3600]), tensor([2.7590]), tensor([3.6900]), tensor([1.5800]), tensor([2.9500]), tensor([3.8050]), tensor([4.0600]), tensor([3.1980]), tensor([3.0520]), tensor([3.0070]), tensor([4.1420]), tensor([3.9700]), tensor([3.3890]), tensor([-0.6600]), tensor([2.2000]), tensor([4.7800]), tensor([3.2500]), tensor([4.2200]), tensor([2.2300]), tensor([4.5920]), tensor([3.5470]), tensor([3.1500]), tensor([4.5700]), tensor([-1.5600]), tensor([2.9800]), tensor([2.6010]), tensor([1.5200]), tensor([4.4200]), tensor([5.8300]), tensor([2.8500]), tensor([4.3000]), tensor([2.3210]), tensor([2.0300]), tensor([0.9500]), tensor([2.9170]), tensor([2.8300]), tensor([1.8100]), tensor([2.9890]), tensor([-0.2000]), tensor([2.9878]), tensor([3.5300]), tensor([1.3600]), tensor([3.5000]), tensor([1.9700]), tensor([2.8000]), tensor([-1.1200]), tensor([3.7400]), tensor([0.8700]), tensor([4.3600]), tensor([2.3900]), tensor([2.6500]), tensor([2.9500]), tensor([3.3860]), tensor([3.6300]), tensor([3.1770]), tensor([2.0900]), tensor([3.3020]), tensor([2.6700]), tensor([3.8480]), tensor([2.2100]), tensor([1.6600]), tensor([2.2900]), tensor([3.2940]), tensor([-1.0430]), tensor([-0.8140]), tensor([3.2900]), tensor([3.5910]), tensor([1.3900]), tensor([-1.5430]), tensor([2.0780]), tensor([3.6950]), tensor([2.5800]), tensor([3.2900]), tensor([-1.3180]), tensor([2.4860]), tensor([3.7940]), tensor([-0.7410]), tensor([1.4000]), tensor([3.0320]), tensor([4.6800]), tensor([-1.5500]), tensor([3.0400]), tensor([2.3950]), tensor([2.3800]), tensor([1.7550]), tensor([2.3320]), tensor([1.7400]), tensor([3.5200]), tensor([4.3500]), tensor([5.3300]), tensor([1.7100]), tensor([2.3450]), tensor([3.5300]), tensor([2.4300]), tensor([0.5310]), tensor([1.5790]), tensor([3.5300]), tensor([0.3800]), tensor([3.4900]), tensor([5.7400]), tensor([-0.0500]), tensor([2.9800]), tensor([2.5300]), tensor([2.1060]), tensor([2.4100]), tensor([-0.8200]), tensor([3.0800]), tensor([2.6500]), tensor([3.5100]), tensor([2.8210]), tensor([2.5800]), tensor([1.5600]), tensor([-0.9000]), tensor([4.4850]), tensor([4.1300]), tensor([2.9200]), tensor([2.3500]), tensor([0.9900]), tensor([0.5470]), tensor([2.3770]), tensor([4.2300]), tensor([2.7540]), tensor([2.8670]), tensor([5.5900]), tensor([2.8110]), tensor([-1.1620]), tensor([2.6600]), tensor([-1.5100]), tensor([-0.0100]), tensor([3.0900]), tensor([3.2600]), tensor([2.9400]), tensor([2.4660]), tensor([2.5500]), tensor([2.3700]), tensor([4.3470]), tensor([2.2540]), tensor([3.0030]), tensor([-0.5500]), tensor([2.9200]), tensor([1.8710]), tensor([5.2830]), tensor([0.6510]), tensor([-1.5800]), tensor([2.7300]), tensor([1.4000]), tensor([1.2000]), tensor([5.4870]), tensor([2.1700]), tensor([2.5300]), tensor([1.6950]), tensor([2.6500]), tensor([2.2940]), tensor([1.3300]), tensor([0.5300]), tensor([3.5900]), tensor([3.0900]), tensor([1.9250]), tensor([3.]), tensor([-1.0900]), tensor([3.3990]), tensor([2.1700]), tensor([0.3500]), tensor([2.7266]), tensor([4.8500]), tensor([0.3300]), tensor([2.8190]), tensor([2.5400]), tensor([3.5470]), tensor([3.1300]), tensor([3.1520]), tensor([2.5330]), tensor([4.6180]), tensor([-0.9800]), tensor([2.9240]), tensor([1.8300]), tensor([2.7100]), tensor([2.4350]), tensor([-0.7710]), tensor([3.2660]), tensor([4.4200]), tensor([-1.1200]), tensor([0.9200]), tensor([3.3400]), tensor([-0.9430]), tensor([2.1900]), tensor([2.5700]), tensor([1.8170]), tensor([2.6000]), tensor([1.9200]), tensor([3.6010]), tensor([3.1510]), tensor([4.1400]), tensor([1.1800]), tensor([-1.5700]), tensor([2.6000]), tensor([3.8000]), tensor([1.5500]), tensor([3.0500]), tensor([2.0200]), tensor([6.0600]), tensor([2.6800]), tensor([0.5100]), tensor([3.8200]), tensor([2.5300]), tensor([0.4570]), tensor([3.3700]), tensor([2.5130]), tensor([2.1100]), tensor([1.9200]), tensor([3.9990]), tensor([3.6610]), tensor([-0.7200]), tensor([2.6200]), tensor([4.0400]), tensor([4.3290]), tensor([2.2000]), tensor([1.3820]), tensor([3.1600]), tensor([2.7460]), tensor([2.9200]), tensor([2.8400]), tensor([2.1600]), tensor([3.4200]), tensor([2.5480]), tensor([2.5300]), tensor([4.4800]), tensor([2.4500]), tensor([2.4000]), tensor([3.9200]), tensor([1.4800]), tensor([1.9500]), tensor([2.9460]), tensor([-1.5600]), tensor([2.7100]), tensor([3.3400]), tensor([-0.7990]), tensor([3.6000]), tensor([1.8200]), tensor([3.9480]), tensor([1.3700]), tensor([3.8800]), tensor([4.8000]), tensor([4.4640]), tensor([3.4000]), tensor([3.3400]), tensor([3.0860]), tensor([4.0980]), tensor([3.5500]), tensor([0.5500]), tensor([3.2200]), tensor([3.0860]), tensor([1.8700]), tensor([4.0700]), tensor([-0.9650]), tensor([5.3030]), tensor([4.7500]), tensor([3.0600]), tensor([4.9000]), tensor([3.0700]), tensor([0.2200]), tensor([3.1000]), tensor([1.9900]), tensor([4.3900]), tensor([3.1040]), tensor([3.9200]), tensor([3.5500]), tensor([4.3000]), tensor([1.8400]), tensor([-1.7800]), tensor([2.1490]), tensor([2.7500]), tensor([4.4900]), tensor([2.5100]), tensor([2.4000]), tensor([3.0370]), tensor([3.1870]), tensor([-0.8400]), tensor([2.1900]), tensor([-1.2200]), tensor([1.9900]), tensor([2.6530]), tensor([3.9900]), tensor([1.5800]), tensor([5.0100]), tensor([2.3400]), tensor([2.7380]), tensor([0.9559]), tensor([3.7000]), tensor([3.8620]), tensor([1.7900]), tensor([0.8400]), tensor([0.9900]), tensor([2.8000]), tensor([0.5440]), tensor([3.0080]), tensor([1.9400]), tensor([1.0560]), tensor([2.9700]), tensor([3.4100]), tensor([2.4700]), tensor([2.3600]), tensor([4.7000]), tensor([1.7300]), tensor([4.5900]), tensor([2.4300]), tensor([3.3660]), tensor([0.8800]), tensor([2.9100]), tensor([1.6600]), tensor([2.6990]), tensor([3.0900]), tensor([2.0200]), tensor([0.3460]), tensor([5.2400]), tensor([3.5258]), tensor([2.3420]), tensor([3.9800]), tensor([3.6500]), tensor([2.2799]), tensor([1.2700]), tensor([2.5300]), tensor([1.9100]), tensor([1.9670]), tensor([2.9700]), tensor([3.7000]), tensor([3.5100]), tensor([0.6500]), tensor([1.5400]), tensor([1.6220]), tensor([5.4200]), tensor([1.6200]), tensor([4.7930]), tensor([0.7100]), tensor([3.1700]), tensor([2.4900]), tensor([1.3200]), tensor([1.9080]), tensor([2.6000]), tensor([0.8610]), tensor([3.8640]), tensor([4.3600]), tensor([4.5400]), tensor([1.6900]), tensor([1.8680]), tensor([3.5700]), tensor([3.6160]), tensor([3.3700]), tensor([3.2400]), tensor([1.6300]), tensor([4.4300]), tensor([0.4900]), tensor([0.6800]), tensor([2.5650]), tensor([3.3164]), tensor([3.6570]), tensor([3.3900]), tensor([4.5200]), tensor([2.1900]), tensor([3.3800]), tensor([-0.5600]), tensor([3.7050]), tensor([2.7590]), tensor([4.0030]), tensor([2.5340]), tensor([-1.1500]), tensor([-1.1300]), tensor([1.5800]), tensor([-0.6100]), tensor([1.7060]), tensor([5.0800]), tensor([2.1540]), tensor([3.0300]), tensor([2.9900]), tensor([2.5640]), tensor([4.4430]), tensor([-0.7600]), tensor([3.7200]), tensor([3.1700]), tensor([3.5500]), tensor([2.9350]), tensor([5.7000]), tensor([-1.9300]), tensor([1.4720]), tensor([-0.5900]), tensor([1.8600]), tensor([2.8650]), tensor([3.2750]), tensor([2.5170]), tensor([2.7900]), tensor([1.9700]), tensor([3.0680]), tensor([5.2900]), tensor([4.1600]), tensor([3.7200]), tensor([3.3200]), tensor([3.2600]), tensor([4.4050]), tensor([1.8180]), tensor([2.7500]), tensor([3.2900]), tensor([4.6500]), tensor([3.4000]), tensor([2.9800]), tensor([0.3400]), tensor([-1.2600]), tensor([-1.3460]), tensor([2.8940]), tensor([2.9320]), tensor([3.3510]), tensor([1.5500]), tensor([4.1900]), tensor([3.1000]), tensor([4.3900]), tensor([3.0320]), tensor([4.5100]), tensor([5.1520]), tensor([2.4400]), tensor([5.4900]), tensor([0.5700]), tensor([2.1780]), tensor([-1.1800]), tensor([3.8600]), tensor([3.7170]), tensor([2.8300]), tensor([-0.3180]), tensor([3.3100]), tensor([2.5800]), tensor([-0.7110]), tensor([1.9080]), tensor([2.2140]), tensor([2.9500]), tensor([3.9400]), tensor([3.9600]), tensor([2.3870]), tensor([-1.5230]), tensor([2.8260]), tensor([-0.4670]), tensor([2.7500]), tensor([2.5600]), tensor([0.8800]), tensor([2.6900]), tensor([2.7200]), tensor([5.2200]), tensor([1.4140]), tensor([3.1100]), tensor([3.9560]), tensor([2.8700]), tensor([3.1300]), tensor([1.4000]), tensor([1.6780]), tensor([2.2600]), tensor([3.6200]), tensor([4.1200]), tensor([3.9800]), tensor([-1.5210]), tensor([3.2080]), tensor([3.7010]), tensor([3.9850]), tensor([2.9700]), tensor([3.6140]), tensor([2.0600]), tensor([4.0970]), tensor([-0.5910]), tensor([-1.3940]), tensor([2.3020]), tensor([0.5030]), tensor([4.1200]), tensor([3.5900]), tensor([2.5730]), tensor([2.4150]), tensor([2.6900]), tensor([2.5400]), tensor([2.3700]), tensor([1.0800]), tensor([0.4260]), tensor([2.0800]), tensor([2.8200]), tensor([3.0090]), tensor([3.6500]), tensor([3.3400]), tensor([3.5600]), tensor([3.1550]), tensor([2.9360]), tensor([1.7760]), tensor([5.8900]), tensor([5.3300]), tensor([2.6370]), tensor([4.6700]), tensor([1.9010]), tensor([-1.4500]), tensor([4.7000]), tensor([3.9840]), tensor([2.8100]), tensor([-1.4500]), tensor([2.3630]), tensor([4.0500]), tensor([3.0700]), tensor([3.8100]), tensor([3.2800]), tensor([2.9300]), tensor([0.3300]), tensor([-0.7280]), tensor([-1.1810]), tensor([3.0500]), tensor([2.7400]), tensor([1.8900]), tensor([4.3900]), tensor([4.3160]), tensor([1.1300]), tensor([0.4400]), tensor([3.2600]), tensor([1.3400]), tensor([1.9730]), tensor([0.5000]), tensor([6.8600]), tensor([2.8800]), tensor([3.4140]), tensor([2.2090]), tensor([1.0200]), tensor([2.4930]), tensor([3.5500]), tensor([4.0120]), tensor([2.1197]), tensor([3.9580]), tensor([3.2900]), tensor([1.9600]), tensor([2.7800]), tensor([-0.2690]), tensor([4.5400]), tensor([3.1850]), tensor([3.3670]), tensor([4.5600]), tensor([3.0610]), tensor([-0.6630]), tensor([3.0600]), tensor([3.4100]), tensor([2.6340]), tensor([2.3200]), tensor([1.9900]), tensor([3.9120]), tensor([3.5090]), tensor([3.1600]), tensor([3.6300]), tensor([3.3200]), tensor([0.4400]), tensor([2.4900]), tensor([3.1000]), tensor([2.8430]), tensor([3.3100]), tensor([4.4920]), tensor([0.7000]), tensor([2.9430]), tensor([3.6600]), tensor([4.2500]), tensor([3.0630]), tensor([3.6400]), tensor([1.9210]), tensor([-0.7200]), tensor([2.0150]), tensor([2.8800]), tensor([2.0420]), tensor([-0.1600]), tensor([2.5000]), tensor([2.8400]), tensor([4.5200]), tensor([3.0400]), tensor([-0.7800]), tensor([2.6601]), tensor([3.7400]), tensor([3.6700]), tensor([3.3200]), tensor([4.0200]), tensor([4.0700]), tensor([2.7606]), tensor([2.0990]), tensor([3.0200]), tensor([6.3900]), tensor([3.3192]), tensor([0.3120]), tensor([2.6700]), tensor([-1.3840]), tensor([3.1700]), tensor([0.1220]), tensor([2.3900]), tensor([1.5400]), tensor([3.0300]), tensor([4.0100]), tensor([3.5310]), tensor([-1.3600]), tensor([2.9500]), tensor([3.5700]), tensor([3.2700]), tensor([1.2160]), tensor([4.4520]), tensor([-0.8600]), tensor([4.5700]), tensor([4.7620]), tensor([2.5080]), tensor([3.6800]), tensor([-0.7010]), tensor([3.1730]), tensor([4.9800]), tensor([-1.8000]), tensor([5.2000]), tensor([3.5200]), tensor([2.8900]), tensor([4.6840]), tensor([-0.7600]), tensor([3.1400]), tensor([3.1820]), tensor([2.8800]), tensor([4.3600]), tensor([3.6400]), tensor([2.0610]), tensor([3.9000]), tensor([3.3900]), tensor([3.1440]), tensor([6.1500]), tensor([2.4400]), tensor([1.3200]), tensor([3.9610]), tensor([2.3300]), tensor([-1.2100]), tensor([0.2620]), tensor([-0.5870]), tensor([3.5700]), tensor([2.7500]), tensor([3.7300]), tensor([6.6400]), tensor([3.6400]), tensor([3.2800]), tensor([3.2300]), tensor([0.7020]), tensor([-0.9500]), tensor([3.3240]), tensor([2.9200]), tensor([2.0200]), tensor([2.7090]), tensor([2.8940]), tensor([4.5200]), tensor([-1.3100]), tensor([0.3600]), tensor([3.6950]), tensor([3.7900]), tensor([3.6800]), tensor([2.4820]), tensor([3.1190]), tensor([1.0250]), tensor([0.5300]), tensor([3.0500]), tensor([2.7810]), tensor([1.1770]), tensor([-1.0600]), tensor([-0.5090]), tensor([1.5300]), tensor([3.6100]), tensor([1.5800]), tensor([1.7090]), tensor([-1.1610]), tensor([3.7800]), tensor([4.0990]), tensor([3.7410]), tensor([3.2670]), tensor([2.8170]), tensor([3.0420]), tensor([5.8600]), tensor([2.8650]), tensor([2.5100]), tensor([4.3460]), tensor([3.6120]), tensor([2.7200]), tensor([2.9492]), tensor([4.7300]), tensor([2.6480]), tensor([0.9900]), tensor([1.4930]), tensor([-0.2590]), tensor([-1.5640]), tensor([-0.4140]), tensor([1.4500]), tensor([-0.4500]), tensor([1.2400]), tensor([4.6760]), tensor([3.5570]), tensor([4.4800]), tensor([3.3000])]\n"
          ]
        }
      ],
      "source": [
        "# combine solvent and solute for train and test data\n",
        "combined_an_tr = solvent_tr_AtomicNum_list + solute_tr_AtomicNum_list\n",
        "combined_e_tr = solvent_tr_Edge_list + solute_tr_Edge_list\n",
        "combined_n_tr = solvent_tr_Natom_list + solute_tr_Natom_list\n",
        "y_g_tr = []\n",
        "for logK in train_data['logK']:\n",
        "    y_g_tr.append(torch.Tensor([logK]))\n",
        "print(y_g_tr)\n",
        "combined_an_te = solvent_te_AtomicNum_list + solute_te_AtomicNum_list\n",
        "combined_e_te = solvent_te_Edge_list + solute_te_Edge_list\n",
        "combined_n_te = solvent_te_Natom_list + solute_te_Natom_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "5kgR1oTWO0oF"
      },
      "outputs": [],
      "source": [
        "X_g_tr = GraphDataset(combined_an_tr, combined_e_tr, combined_n_tr, y_g_tr)\n",
        "X_g_te = GraphDataset(combined_an_te, combined_e_te, combined_n_te)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "N09Mt-82PEWc"
      },
      "outputs": [],
      "source": [
        "def collate_graphs(batch):\n",
        "    '''Batch multiple graphs into one batched graph\n",
        "\n",
        "    Args:\n",
        "\n",
        "        batch (tuple): tuples of AtomicNum, Edge, Natom and y obtained from GraphDataset.__getitem__()\n",
        "\n",
        "    Return\n",
        "        (tuple): Batched AtomicNum, Edge, Natom, y\n",
        "\n",
        "    '''\n",
        "\n",
        "    AtomicNum_batch = []\n",
        "    Edge_batch = []\n",
        "    Natom_batch = []\n",
        "    y_batch = []\n",
        "\n",
        "    cumulative_atoms = np.cumsum([0] + [b[2] for b in batch])[:-1]\n",
        "\n",
        "    for i in range(len(batch)):\n",
        "        z, a, N, y = batch[i]\n",
        "        if i >= len(X_g_tr):\n",
        "            return None, None, None, None\n",
        "        index_shift = cumulative_atoms[i]\n",
        "        a = a + index_shift\n",
        "        AtomicNum_batch.append(z)\n",
        "        Edge_batch.append(a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "CWhl3qYiPRQc"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_g_loader = DataLoader(X_g_tr,\n",
        "                          batch_size=512,\n",
        "                          collate_fn=collate_graphs,shuffle=True)\n",
        "test_g_loader = DataLoader(X_g_te,\n",
        "                          batch_size=512,\n",
        "                          collate_fn=collate_graphs,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "jj5s8Na3P24q"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GNN(torch_geometric.nn.models.GCN):\n",
        "    def __init__(self, n_convs=3, n_embed=64):\n",
        "        # Intatiate GCN\n",
        "        super(GNN, self).__init__(-1,n_embed,n_convs)\n",
        "        # Declare 1 hot encoding\n",
        "        self.atom_embed = nn.Embedding(100, n_embed)\n",
        "        # Declare readout layers\n",
        "        self.readout = nn.Sequential(nn.Linear(n_embed, n_embed), nn.ReLU(), nn.Linear(n_embed, 1))\n",
        "    def forward(self, AtomicNum, Edge, Natom):\n",
        "        # Parametrize embedding\n",
        "        h = self.atom_embed(AtomicNum)\n",
        "        # Graph convolutions\n",
        "        h = super(GNN, self).forward(h,Edge)\n",
        "        # Node wise output\n",
        "        node_out = self.readout(h)\n",
        "        # Split nodes back to graphs\n",
        "        node_splits = torch.split(node_out, Natom)\n",
        "        output = torch.stack([i.sum() for i in node_splits])\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "9OmqwPi6QFaI"
      },
      "outputs": [],
      "source": [
        "def loop(model, loader, epoch, evaluation=False):\n",
        "\n",
        "    if evaluation:\n",
        "        model.eval()\n",
        "        mode = \"eval\"\n",
        "    else:\n",
        "        model.train()\n",
        "        mode = 'train'\n",
        "    batch_losses = []\n",
        "\n",
        "    # Define tqdm progress bar\n",
        "    tqdm_data = tqdm(loader, position=0, leave=False, desc='{} (epoch #{})'.format(mode, epoch))\n",
        "\n",
        "    for data in tqdm_data:\n",
        "\n",
        "        AtomicNumber, Edge, Natom, y = data\n",
        "        AtomicNumber = AtomicNumber.to(device)\n",
        "        Edge = Edge.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(AtomicNumber, Edge, Natom)\n",
        "        loss = (pred-y).pow(2).mean() # MSE loss\n",
        "\n",
        "        if not evaluation:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_losses.append(loss.item())\n",
        "\n",
        "        postfix = ['batch loss={:.3f}'.format(loss.item()) ,\n",
        "                   'avg. loss={:.3f}'.format(np.array(batch_losses).mean())]\n",
        "\n",
        "        tqdm_data.set_postfix_str(' '.join(postfix))\n",
        "\n",
        "    return np.array(batch_losses).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9Fvyft0x37mG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "U7NfJlmNQqy9"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "device = 'cuda:0'\n",
        "model_gnn = GNN(n_convs=4, n_embed=128).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model_gnn.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=50)\n",
        "\n",
        "for epoch in range(10):\n",
        "    train_loss = loop(model_gnn, train_g_loader, epoch)\n",
        "    # Optionally, update the learning rate using the scheduler\n",
        "    scheduler.step(train_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "XxNMtpGfSziN"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, device):\n",
        "\n",
        "    '''\n",
        "    A function to return the predicted solubility (for evaluation).\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): your sequence classifier\n",
        "        dataloader (torch.utils.data.Dataloader): DataLoader object for the train data\n",
        "        device (str): Your device\n",
        "\n",
        "    Returns:\n",
        "        (np.array, np.array): true values, predicted values\n",
        "    '''\n",
        "\n",
        "    y_pred_list = []\n",
        "    # y_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for batch in dataloader:\n",
        "\n",
        "            AtomicNumber, Edge, Natom = batch\n",
        "            AtomicNumber = AtomicNumber.to(device)\n",
        "            Edge = Edge.to(device)\n",
        "            # y = y.to(device)\n",
        "            y_pred = model(AtomicNumber, Edge, Natom)\n",
        "\n",
        "            y_pred_list+=y_pred.detach().cpu().numpy().tolist()\n",
        "            # y_list+=y.detach().cpu().numpy().tolist()\n",
        "\n",
        "    return np.array(y_pred_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "3t69X-1Y3idO",
        "outputId": "cb58a04b-40cc-49cd-ebf4-857fe2a99fac"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-d9b9882a3dc7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_g_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-cfea3ca69edd>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mAtomicNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNatom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-f5b8fbc3ea2f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mAtomicNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNatom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "y_train, y_train_pred = evaluate(model_gnn, train_g_loader, device)\n",
        "train_r2 = r2_score(y_train,y_train_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEB2bdgr2W1E"
      },
      "source": [
        "## 2.5 Augmenting MLP model with attention mechanism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk3EKCit2hEr",
        "outputId": "49510ab4-3998-4c94-9d9b-c782c3b5e554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test R^2 Score: 0.04590015436123629\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "\n",
        "input_tensor = torch.tensor(X_train_fp, dtype=torch.float32)\n",
        "target_tensor = torch.tensor(y_tr, dtype=torch.float32)\n",
        "\n",
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, input_tensor, target_tensor):\n",
        "        self.input_data = input_tensor\n",
        "        self.target_data = target_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_data[idx], self.target_data[idx]\n",
        "\n",
        "# Create DataLoader for training data\n",
        "train_dataset = CustomDataset(input_tensor, target_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define MLP model with attention mechanism\n",
        "class MLPWithAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPWithAttention, self).__init__()\n",
        "        self.fc0 = nn.Linear(218, 218)\n",
        "        self.fc1 = nn.Linear(218, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_weights = torch.softmax(self.fc0(x), dim=1)\n",
        "        x = x * attn_weights\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, criterion, and optimizer\n",
        "mlp_attention_model = MLPWithAttention()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(mlp_attention_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_input, batch_target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = mlp_attention_model(batch_input)\n",
        "        loss = criterion(outputs, batch_target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "with torch.no_grad():\n",
        "    output_test = mlp_attention_model(input_tensor)\n",
        "    test_r2_score = r2_score(target_tensor.numpy(), output_test.numpy())\n",
        "\n",
        "# Print the result\n",
        "print(\"Test R^2 Score:\", test_r2_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdGac8q96TzA"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "a2KRbdTc6Wq4"
      },
      "outputs": [],
      "source": [
        "# In conclusion, the highest accuracy is achieved using gradient boosting with feature set of morgan fingerprint\n",
        "# data and other chemical properties from rdkit.\n",
        "# As we mentioned before, gradient boosting model does good job in learning interactions by\n",
        "# starting with simple decision tree, and adding new tree adn tries to explain the error left behind the previous tree.\n",
        "# when feature interacts with another feature to influence the target variable, the ensemble of trees can learn these relationships.\n",
        "# By minimazing loss gradient during training, it learns interactions and improve the accuracy of the model."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:ps3]",
      "language": "python",
      "name": "conda-env-ps3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
